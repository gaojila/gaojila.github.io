[{"categories":["Prometheus"],"content":"背景 非容器下prometheus高可用体系调研 参数 联邦 Thanos VictoraMetrics 长期存储 小于一个月 永久（对象存储） 俩个月（可用本地盘存储） grafana配置 联邦节点，有oom风险 query， 长期存储读storegateway， 短期读本都盘（指标过多未拆分时有oom风险） vmselect， 不使用prometheus，使用vmagent采集数据，比prometheus内存消耗更小，数据查询读vmselect prometheus多副本 依赖亲和或standby机制，一般只有一个副本提供数据，service亲和 支持去重（副本重启数据不会断） 支持去重（副本重启数据不会断） 部署 简单 复杂 简单 资源使用 多 最多 较多 ","date":"2021-05-07","objectID":"/victoriametrics%E5%AE%9E%E7%8E%B0prometheus%E9%AB%98%E5%8F%AF%E7%94%A8/:1:0","tags":["Prometheus + Grafana"],"title":"VictoriaMetrics实现Prometheus高可用","uri":"/victoriametrics%E5%AE%9E%E7%8E%B0prometheus%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"categories":["blog"],"content":"背景 科学上网 反复被ban 符合自己气质的域名 博客掩护科学上网 免费证书自动续期 ","date":"2021-03-10","objectID":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/:0:0","tags":["hugo","hexo"],"title":"Github Action自动发布到伺服器","uri":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/"},{"categories":["blog"],"content":"科学上网 v2ray 也不是那么安全了,每个月都会被ban一次 ","date":"2021-03-10","objectID":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/:1:0","tags":["hugo","hexo"],"title":"Github Action自动发布到伺服器","uri":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/"},{"categories":["blog"],"content":"域名注册 阿里云注册域名,还好我这蹩脚的域名没人注册 ","date":"2021-03-10","objectID":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/:2:0","tags":["hugo","hexo"],"title":"Github Action自动发布到伺服器","uri":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/"},{"categories":["blog"],"content":"自动发布博客到伺服器 ssh-keygen 生成密钥对 ❯ ssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\" Generating public/private rsa key pair. Your identification has been saved in gh-pages. Your public key has been saved in gh-pages.pub. The key fingerprint is: SHA256:qm3ZlWXDEwfSwxmqMIQAzcDyasdfasdfuqioweqnslfansd0 redgaojila@gmail.com The key's randomart image is: +---[RSA 4096]----+ |+=.. .. .oo+ | |..+ .. o* . | |.= o .. + | |.o+ o . * | |*=.. S + o | |==o . o | |*o ..o . | |B.o .oE . | | = ..o. | +----[SHA256]-----+ ❯ ll gh-pages* Permissions Size User Date Modified Name .rw------- 3.4k redgaojila 29 1 14:00 gh-pages .rw-r--r-- 746 redgaojila 29 1 14:00 gh-pages.pub 私钥配置和公钥配置 私钥配置 公钥配置 配置Github Action(同时发布到Github Page) name:Hugoon:push:branches:- masterjobs:build:runs-on:ubuntu-lateststeps:- name:checkoutuses:actions/checkout@masterwith:submodules:true- name:Setup Hugouses:peaceiris/actions-hugo@v2.4.13with:hugo-version:'0.80.0'extended:true- name:Hugo Buildrun:hugo --gc --minify --buildFuture --cleanDestinationDir- name:Install algolia modulerun:npm install atomic-algolia --save-dev- name:Init algoliarun:npm run algolia- name:Deploy Privateenv:ACTIONS_DEPLOY_KEY:${{ secrets.PRIVATE_ACTIONS_DEPLOY_KEY }}HOST:www.gaojila.redUSER:rootHOME_PATH:/var/wwwDEVELOP_SH_PATH:/var/www/develop.shPACKAGE_NAME:public.tar.gzDEVELOP_DIR:gaojila.redBACKUP_DIR:backuprun:|SSH_PATH=\"$HOME/.ssh\" mkdir -p $SSH_PATH touch \"$SSH_PATH/known_hosts\" echo \"$ACTIONS_DEPLOY_KEY\" \u003e \"$SSH_PATH/id_rsa\" chmod 700 \"$SSH_PATH\" chmod 600 \"$SSH_PATH/known_hosts\" chmod 600 \"$SSH_PATH/id_rsa\" eval $(ssh-agent) ssh-add \"$SSH_PATH/id_rsa\" ssh-keyscan -t rsa $HOST \u003e\u003e \"$SSH_PATH/known_hosts\" cd public tar -cf $PACKAGE_NAME * scp $PACKAGE_NAME $USER@$HOST:$HOME_PATH ssh -o StrictHostKeyChecking=no -i $SSH_PATH/id_rsa -A -tt $USER@$HOST sh $DEVELOP_SH_PATH \\ -d $HOME_PATH/$DEVELOP_DIR -b $HOME_PATH/$BACKUP_DIR -f $HOME_PATH/$PACKAGE_NAME exit- name:Deploy Githubuses:peaceiris/actions-gh-pages@v3.7.3with:DEPLOY_KEY:${{ secrets.ACTIONS_DEPLOY_KEY }}EXTERNAL_REPOSITORY:gaojila/gaojila.github.ioPUBLISH_BRANCH:masterPUBLISH_DIR:./public 服务器内部的解包和备份由服务器内脚本develop.sh解决 root@private:/var/www# cat develop.sh #!/bin/sh set -e FILE_NAME=`basename $0` #说明 show_usage=\"usage:$FILE_NAME[-d develop_path,-b backup_path -f file_path]\" #参数 # 本地仓库目录 opt_develop_path=\"\" # 备份目录 opt_backup_path=\"\" # 部署文件 opt_file_path=\"\" GETOPT_ARGS=`getopt -o d🅱️f: -al develop_path:,backup_path:,file_path: -- \"$@\"` eval set -- \"$GETOPT_ARGS\" #获取参数 while [ -n \"$1\" ] do case \"$1\" in -d|--develop_path) opt_develop_path=$2; shift 2;; -b|--backup_path) opt_backup_path=$2; shift 2;; -f|--opt_file_path) opt_file_path=$2; shift 2;; --) break ;; *) echo $1,$2,$show_usage; break ;; esac done # 判断参数 if [[ -z $opt_develop_path || -z $opt_backup_path || -z $opt_file_path ]]; then echo -e $show_usage exit 0 fi if [ \"$opt_develop_path\" = \"$opt_backup_path\" ]; then echo 'develop_path eq backup_path' exit 0 fi # 判断部署文件是否存在 if [ ! -f $opt_file_path ]; then echo \"$opt_file_pathfile does not exist\" exit 0 fi # 判断文件夹是否存在 if [ ! -x $opt_develop_path ]; then mkdir $opt_develop_path fi # 判断文件夹是否存在 if [ ! -x $opt_backup_path ]; then mkdir $opt_backup_path fi # 文件夹不是空的 if [ ! \"`ls -A $opt_develop_path`\" = \"\" ]; then cd $opt_develop_path tar -cf $opt_backup_path/$(date +%Y%m%d%H%M).tar.gz $opt_develop_path/* rm -rf $opt_develop_path/* fi # 解压文件 tar -xf $opt_file_path -C $opt_develop_path echo \"publish success!\" 配置服务器nginx server { listen 443 ssl; server_name gaojila.red; ssl_certificate /etc/letsencrypt/archive/www.gaojila.red/fullchain1.pem; ssl_certificate_key /etc/letsencrypt/archive/www.gaojila.red/privkey1.pem; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; #默认请求 location / { root /var/www/gaojila.red; index index.html index.xml; } } server { listen 80; server_name gaojila.red; rewrite ^(.*) https://$host$1 permane","date":"2021-03-10","objectID":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/:3:0","tags":["hugo","hexo"],"title":"Github Action自动发布到伺服器","uri":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/"},{"categories":["blog"],"content":"证书自动续期 添加如下定时任务,会自动检测到期 0 3 */7 * * /usr/bin/certbot renew --renew-hook \"/usr/bin/nginx -s reload\" ","date":"2021-03-10","objectID":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/:4:0","tags":["hugo","hexo"],"title":"Github Action自动发布到伺服器","uri":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/"},{"categories":["blog"],"content":"如何搭建新一代的xray科学上网本文不做解释 ","date":"2021-03-10","objectID":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/:5:0","tags":["hugo","hexo"],"title":"Github Action自动发布到伺服器","uri":"/github-action%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%88%B0%E4%BC%BA%E6%9C%8D%E5%99%A8/"},{"categories":["linux(🐧)"],"content":"解决ArchLinux用NetworkManager和wpa_suppicant连接wifi反复重连 ","date":"2021-02-08","objectID":"/archlinux%E5%8F%8D%E5%A4%8D%E9%87%8D%E8%BF%9Ewifi%E8%A7%A3%E5%86%B3/:1:0","tags":["archlinux"],"title":"ArchLinux反复重连wifi解决","uri":"/archlinux%E5%8F%8D%E5%A4%8D%E9%87%8D%E8%BF%9Ewifi%E8%A7%A3%E5%86%B3/"},{"categories":["linux(🐧)"],"content":"背景 家用路由器改为ap模式后，wifi反复重连，正常路由模式未出现这种现象。 ","date":"2021-02-08","objectID":"/archlinux%E5%8F%8D%E5%A4%8D%E9%87%8D%E8%BF%9Ewifi%E8%A7%A3%E5%86%B3/:1:1","tags":["archlinux"],"title":"ArchLinux反复重连wifi解决","uri":"/archlinux%E5%8F%8D%E5%A4%8D%E9%87%8D%E8%BF%9Ewifi%E8%A7%A3%E5%86%B3/"},{"categories":["linux(🐧)"],"content":"原因 ArchLinux尽然默认使用NetworkManager到内置到dhcp，内置dhcp服务和ArchLinux本地的dhcp服务冲突。 ","date":"2021-02-08","objectID":"/archlinux%E5%8F%8D%E5%A4%8D%E9%87%8D%E8%BF%9Ewifi%E8%A7%A3%E5%86%B3/:1:2","tags":["archlinux"],"title":"ArchLinux反复重连wifi解决","uri":"/archlinux%E5%8F%8D%E5%A4%8D%E9%87%8D%E8%BF%9Ewifi%E8%A7%A3%E5%86%B3/"},{"categories":["linux(🐧)"],"content":"解决方法 更改dhcpcd的配置文件/etc/dhcpcd.conf，将duid改为clientid，然后重启服务。 systemctl restart dhcpcd@[interface].service 安装上dhclient。 sudo pacman -S dhclient /etc/NetworkManager/NetworkManager.conf 这个配置文件，增加。 [main] dhcp = dhclient 重启服务。 sudo systemctl restart NetworkManager ","date":"2021-02-08","objectID":"/archlinux%E5%8F%8D%E5%A4%8D%E9%87%8D%E8%BF%9Ewifi%E8%A7%A3%E5%86%B3/:1:3","tags":["archlinux"],"title":"ArchLinux反复重连wifi解决","uri":"/archlinux%E5%8F%8D%E5%A4%8D%E9%87%8D%E8%BF%9Ewifi%E8%A7%A3%E5%86%B3/"},{"categories":["blog"],"content":"背景 12月Travis Ci 不再为开源项目提供支持，故转战Github Action ","date":"2021-01-29","objectID":"/travis-ci%E8%BD%AC%E5%88%B0github-action/:1:0","tags":["hugo","hexo"],"title":"Travis Ci转到Github Action","uri":"/travis-ci%E8%BD%AC%E5%88%B0github-action/"},{"categories":["blog"],"content":"准备工作 生成对称密钥 配置源码仓库和发布仓库密钥 配置Github Action ","date":"2021-01-29","objectID":"/travis-ci%E8%BD%AC%E5%88%B0github-action/:2:0","tags":["hugo","hexo"],"title":"Travis Ci转到Github Action","uri":"/travis-ci%E8%BD%AC%E5%88%B0github-action/"},{"categories":["blog"],"content":"开始 ","date":"2021-01-29","objectID":"/travis-ci%E8%BD%AC%E5%88%B0github-action/:3:0","tags":["hugo","hexo"],"title":"Travis Ci转到Github Action","uri":"/travis-ci%E8%BD%AC%E5%88%B0github-action/"},{"categories":["blog"],"content":"生成对称密钥 ❯ ssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\" Generating public/private rsa key pair. Your identification has been saved in gh-pages. Your public key has been saved in gh-pages.pub. The key fingerprint is: SHA256:qm3ZlWXDEwfSwxmqMIQAzcDyasdfasdfuqioweqnslfansd0 redgaojila@gmail.com The key's randomart image is: +---[RSA 4096]----+ |+=.. .. .oo+ | |..+ .. o* . | |.= o .. + | |.o+ o . * | |*=.. S + o | |==o . o | |*o ..o . | |B.o .oE . | | = ..o. | +----[SHA256]-----+ ❯ ll gh-pages* Permissions Size User Date Modified Name .rw------- 3.4k redgaojila 29 1 14:00 gh-pages .rw-r--r-- 746 redgaojila 29 1 14:00 gh-pages.pub ","date":"2021-01-29","objectID":"/travis-ci%E8%BD%AC%E5%88%B0github-action/:3:1","tags":["hugo","hexo"],"title":"Travis Ci转到Github Action","uri":"/travis-ci%E8%BD%AC%E5%88%B0github-action/"},{"categories":["blog"],"content":"配置源码仓库和发布仓库密钥 此处填入私钥设置私钥名称(ACTIONS_DEPLOY_KEY) 此处填入公钥 ","date":"2021-01-29","objectID":"/travis-ci%E8%BD%AC%E5%88%B0github-action/:3:2","tags":["hugo","hexo"],"title":"Travis Ci转到Github Action","uri":"/travis-ci%E8%BD%AC%E5%88%B0github-action/"},{"categories":["blog"],"content":"配置Github Action 选择workflow 配置workflow name:Hugoon:push:branches:- masterjobs:build:runs-on:ubuntu-lateststeps:- name:checkoutuses:actions/checkout@masterwith:submodules:true- name:Setup Hugouses:peaceiris/actions-hugo@v2.4.13with:hugo-version:'0.80.0'extended:true- name:Hugo Buildrun:hugo --gc --minify --buildFuture --cleanDestinationDir- name:Install algolia modulerun:npm install atomic-algolia --save-dev- name:Init algoliarun:npm run algolia- name:Deployuses:peaceiris/actions-gh-pages@v3.7.3with:DEPLOY_KEY:${{ secrets.ACTIONS_DEPLOY_KEY }}## 此处为之前配置到私钥名称EXTERNAL_REPOSITORY:gaojila/gaojila.github.ioPUBLISH_BRANCH:masterPUBLISH_DIR:./public ","date":"2021-01-29","objectID":"/travis-ci%E8%BD%AC%E5%88%B0github-action/:3:3","tags":["hugo","hexo"],"title":"Travis Ci转到Github Action","uri":"/travis-ci%E8%BD%AC%E5%88%B0github-action/"},{"categories":["Prometheus"],"content":"PromQL 常用函数 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:0:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"abs() abs(v instant-vector)返回输入向量，所有样本值都转换为其绝对值。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:1:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"absent() absent(v instant-vector)如果传递给它的向量具有任何元素，则返回空向量;如果传递给它的向量没有元素，则返回值为 1 的 1 元素向量。 这对于在给定度量标准名称和标签组合不存在时间序列时发出警报非常有用。 absent(nonexistent{job=\"myjob\"}) # =\u003e {job=\"myjob\"} absent(nonexistent{job=\"myjob\", instance=~\".*\"}) # =\u003e {job=\"myjob\"} absent(sum(nonexistent{job=\"myjob\"})) # =\u003e {} 第在二个例子中，absent()试图从输入向量中导出 1 元素输出向量的标签。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:2:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"ceil() ceil(v instant-vector) 将 v 中所有元素的样本值舍入到最接近的整数。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:3:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"changes() 对于每个输入时间系列，changes(v range-vector) 将返回其值在所提供的时间范围内更改的次数作为即时向量。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:4:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"clamp_max() clamp_max(v instant-vector, max scalar)钳制 v 中所有元素的样本值，使其上限为 max。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:5:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"clamp_min() clamp_min(v instant-vector, min scalar)钳制 v 中所有元素的样本值，使其下限为 min。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:6:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"day_of_month() day_of_month(v=vector(time()) instant-vector)返回 UTC 中每个给定时间的月中的某天。 返回值为 1 到 31。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:7:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"day_of_week() day_of_week(v=vector(time()) instant-vector)返回 UTC 中每个给定时间的星期几。 返回值为 0 到 6，其中 0 表示星期日等。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:8:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"days_in_month() days_in_month(v=vector(time()) instant-vector)返回 UTC 中每个给定时间的月中天数。 返回值为 28 到 31。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:9:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"hour() hour(v=vector(time()) instant-vector)返回 UTC 中每个给定时间的一天中的小时。 返回值为 0 到 23。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:10:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"minute() minute(v=vector(time()) instant-vector)以 UTC 为单位返回每个给定时间的分钟。 返回值为 0 到 59。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:11:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"month() month(v=vector(time()) instant-vector)返回 UTC 中每个给定时间的一年中的月份。 返回值为 2 到 12，其中 1 表示 1 月等。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:12:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"year() year(v=vector(time()) instant-vector)以 UTC 格式返回每个给定时间的年份。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:13:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"time() time()返回自 1970 年 1 月 1 日 UTC 以来的秒数。 请注意，这实际上并不返回当前时间，而是返回计算表达式的时间。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:14:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"timestamp() timestamp(v instant-vector)返回给定向量的每个样本的时间戳，作为自 1970 年 1 月 1 日 UTC 以来的秒数。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:15:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"delta() delta(v range-vector)计算范围向量 v 中每个时间系列元素的第一个和最后一个值之间的差值，返回具有给定增量和等效标签的即时向量。 delta 被外推以覆盖范围向量选择器中指定的全时间范围，因此即使样本值都是整数，也可以获得非整数结果。delta 应仅用于仪表。 以下示例表达式返回现在和2小时之前CPU温度的差异： delta(cpu_temp_celsius{host=\"zeus\"}[2h]) ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:16:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"idelta() idelta(v range-vector)计算范围向量 v 中最后两个样本之间的差异，返回具有给定增量和等效标签的即时向量。idelta只能用于仪表。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:17:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"deriv() deriv(v range-vector)函数，计算一个范围向量 v 中各个时间序列二阶导数，使用简单线性回归,deriv应仅用于仪表。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:18:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"floor() floor(v instant-vector)将 v 中所有元素的样本值舍入为最接近的整数。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:19:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"histogram_quantile() histogram_quatile(φ float, b instant-vector) 计算 b 向量的 φ-直方图 (0 ≤ φ ≤ 1) 。（有关 φ-分位数的详细解释和直方图度量类型的使用，请参见直方图和摘要。）b 中的样本是每个桶中的观察计数。 每个样本必须具有标签 le，其中标签值表示桶的包含上限。 （没有这种标签的样本会被忽略。）直方图度量标准类型自动提供带有_bucket 后缀和相应标签的时间序列。 使用 rate()函数指定分位数计算的时间窗口。 示例：直方图度量标准称为 http_request_duration_seconds。 要计算过去 10m 内请求持续时间的第 90 个百分位数，请使用以下表达式： histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[10m])) 在 http_request_duration_seconds 中为每个标签组合计算分位数。 要聚合，请在 rate()函数周围使用 sum()聚合器。 由于 histogram_quantile()需要 le 标签，因此必须将其包含在 by 子句中。 以下表达式按作业聚合第 90 个百分点： histogram_quantile(0.9, sum(rate(http_request_duration_seconds_bucket[10m])) by (job, le)) 要聚合所有内容，请仅指定 le 标签： histogram_quantile(0.9, sum(rate(http_request_duration_seconds_bucket[10m])) by (le)) histogram_quantile()函数通过假设桶内的线性分布来插值分位数值。 最高桶必须具有+Inf 的上限。 （否则，返回 NaN。）如果分位数位于最高桶中，则返回第二个最高桶的上限。 如果该桶的上限大于 0，则假设最低桶的下限为 0.在这种情况下，在该桶内应用通常的线性插值。 否则，对于位于最低桶中的分位数，返回最低桶的上限。 如果 b 包含少于两个桶，则返回 NaN。 对于 φ\u003c0，返回-Inf。 对于 φ\u003e 1，返回+Inf。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:20:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"holt_winters() holt_winters(v range-vector, sf scalar, tf scalar)根据 v 中的范围产生时间序列的平滑值。平滑因子 sf 越低，对旧数据的重要性越高。 趋势因子 tf 越高，则考虑的数据趋势越多。 sf 和 tf 都必须介于 0 和 1 之间。holt_winters只能用于仪表。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:21:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"increase() increase(v range-vector)计算范围向量中时间序列的增加。 单调性中断（例如由于目标重启而导致的计数器重置）会自动调整。 增加外推以覆盖范围向量选择器中指定的全时间范围，因此即使计数器仅以整数增量增加，也可以获得非整数结果。 以下示例表达式返回范围向量中每个时间系列在过去5分钟内测量的HTTP请求数： increase(http_requests_total{job=\"api-server\"}[5m]) increase只应与counters一起使用。 它是rate(v)的语法糖乘以指定时间范围窗口下的秒数，应该主要用于人类可读性。 在记录规则中使用rate，以便每秒一致地跟踪增量。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:22:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"exp() exp(v instant-vector)计算 v 中所有元素的指数函数。特殊情况是： xp(+inf) = +Inf Exp(NaN) = NaN ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:23:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"ln() ln(v instance-vector)计算 v 中所有元素的自然对数。特殊情况是： ln(+Inf) = +Inf ln(0) = -Inf ln(x\u003c0) = NaN ln(NaN) = NaN ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:24:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"log2() log2(v instant-vector)计算 v 中所有元素的二进制对数。特殊情况等同于 ln 中的特殊情况。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:25:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"log10() log10(v instant-vector)计算 v 中所有元素的 10 进制对数。特殊情况等同于 ln 中的特殊情况。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:26:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"sqrt() sqrt(v instant-vector)计算 v 中所有元素的平方根。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:27:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"predict_linear() predict_linear(v range-vector, t scalar)根据范围向量 v 使用线性回归预测从现在起 t 秒的时间序列值。predict_linear只应与仪表一起使用。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:28:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"rate() rate(v range-vector)计算范围向量中时间序列的每秒平均增长率。 单调性中断（例如由于目标重启而导致的计数器重置）会自动调整。 此外，计算推断到时间范围的末端，允许错过刮擦或刮擦循环与范围的时间段的不完美对齐。 以下示例表达式返回范围向量中每个时间系列在过去5分钟内测量的每秒HTTP请求率： rate(http_requests_total{job=\"api-server\"}[5m]) rate应仅用于计数器。 它最适用于警报和缓慢移动计数器的图形。 注意，当将rate()与聚合运算符（例如sum()）或随时间聚合的函数（任何以_over_time结尾的函数）组合时，始终首先采用rate()，然后聚合。 否则，当目标重新启动时，rate()无法检测计数器重置。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:29:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"irate() irate(v range-vector)计算范围向量中时间序列的每秒即时增长率。 这基于最后两个数据点。 单调性中断（例如由于目标重启而导致的计数器重置）会自动调整。 以下示例表达式返回范围向量中每个时间序列的两个最新数据点的最多5分钟的HTTP请求的每秒速率： irate(http_requests_total{job=\"api-server\"}[5m]) 只应在绘制易失性快速移动计数器时使用irate。 警报和缓慢移动计数器的使用率，因为速率的简短更改可以重置FOR子句，并且难以阅读完全由稀有峰值组成的图形。 注意，当将irate()与聚合运算符（例如sum()）或随时间聚合的函数（任何以_over_time结尾的函数）组合时，请始终首先采用irate()，然后进行聚合。 否则，当目标重新启动时，irate()无法检测计数器重置。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:30:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"resets() 对于每个时序数据，resets()在所提供的时间范围内返回计数器重置次数作为即时向量。 两个连续样本之间的值的任何减少都被解释为计数器重置。 resets()只应与计数器一起使用。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:31:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"round() round(v instant-vector, to_nearest 1= scalar)将 v 中所有元素的样本值舍入为最接近的整数。 通过四舍五入解决关系。 可选的 to_nearest 参数允许指定样本值应舍入的最近倍数。 这个倍数也可能是一个分数。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:32:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"scalar() 给定单元素输入向量，scalar(v instant-vector)将该单个元素的样本值作为标量返回。 如果输入向量不具有恰好一个元素，则 scalar 将返回 NaN ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:33:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"sort() sort(v instant-vector)返回按其样本值排序的向量元素，按升序排列。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:34:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"sort_desc() sort(v instant-vector)和sort()相同，但按降序排序。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:35:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"vector() vector(s scalar)将标量 s 作为没有标签的向量返回。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:36:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["Prometheus"],"content":"_over_time() 以下函数允许聚合给定范围向量的每个系列随时间的变化并返回具有每系列聚合结果的即时向量： avg_over_time(range-vector): 范围向量内每个度量指标的平均值。 min_over_time(range-vector): 范围向量内每个度量指标的最小值。 max_over_time(range-vector): 范围向量内每个度量指标的最大值。 sum_over_time(range-vector): 范围向量内每个度量指标的求和值。 count_over_time(range-vector): 范围向量内每个度量指标的样本数据个数。 quantile_over_time(scalar, range-vector): 范围向量内每个度量指标的样本数据值分位数，φ-quantile (0 ≤ φ ≤ 1) stddev_over_time(range-vector): 范围向量内每个度量指标的总体标准偏差。 stdvar_over_time(range-vector): 范围向量内每个度量指标的总体标准方差。 请注意，即使值在整个时间间隔内的间隔不均匀，指定时间间隔内的所有值在聚合中都具有相同的权重。 ","date":"2020-08-31","objectID":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/:37:0","tags":["PromQL"],"title":"PromQL常用函数","uri":"/promql%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"},{"categories":["CKA"],"content":"题目 监控 foobar Pod 的日志，提取 pod 相应的行'error'写入到/logs 文件中 ","date":"2020-07-10","objectID":"/cka2.kubectl-logs/:1:0","tags":["容器(🚢)"],"title":"CKA(2.kubectl logs)","uri":"/cka2.kubectl-logs/"},{"categories":["CKA"],"content":"解题 查看 pod 的日志，是使用 kubelet logs 命令,选项如下: Options: --all-containers=false: Get all containers' logs in the pod(s). -c, --container='': Print the logs of this container -f, --follow=false: Specify if the logs should be streamed. --ignore-errors=false: If watching / following pod logs, allow for any errors that occur to be non-fatal --insecure-skip-tls-verify-backend=false: Skip verifying the identity of the kubelet that logs are requested from. In theory, an attacker could provide invalid log content back. You might want to use this if your kubelet serving certificates have expired. --limit-bytes=0: Maximum bytes of logs to return. Defaults to no limit. --max-log-requests=5: Specify maximum number of concurrent logs to follow when using by a selector. Defaults to 5. --pod-running-timeout=20s: The length of time (like 5s, 2m, or 3h, higher than zero) to wait until at least one pod is running --prefix=false: Prefix each log line with the log source (pod name and container name) -p, --previous=false: If true, print the logs for the previous instance of the container in a pod if it exists. -l, --selector='': Selector (label query) to filter on. --since=0s: Only return logs newer than a relative duration like 5s, 2m, or 3h. Defaults to all logs. Only one of since-time / since may be used. --since-time='': Only return logs after a specific date (RFC3339). Defaults to all logs. Only one of since-time / since may be used. --tail=-1: Lines of recent log file to display. Defaults to -1 with no selector, showing all log lines otherwise 10, if a selector is provided. --timestamps=false: Include timestamps on each line in the log output Usage: kubectl logs [-f] [-p] (POD | TYPE/NAME) [-c CONTAINER] [options] Use \"kubectl options\" for a list of global command-line options (applies to all commands). 对于一般的查看，只需要使用 kubectl logs podname 就可以了 root@shein-mointor-lab-01:~# kubectl logs node-exporter-pfw4v -n kube-monitorc -c, --container='': Print the logs of this container 在查看 pod 的日志时，如果 pod 中只有一个容器，那么不用这个选项，如果 pod 中有多个容器，我们就需要指定其中一个。 比如我们的 pod kucc 中有 4 个容器，redis，nginx，memcached 和 consul，我们要看 redis 的日志，直接访问 pod 的日志是不可以的，必须加上 -c 指定 redis 容器 kubectl logs kucc -c redis -f, --follow=false: Specify if the logs should be streamed. 类似 tail -f kubectl logs -f kucc -c redis -l, --selector='': Selector (label query) to filter on. 这个和 kubectl get 的-l 是一样的，是选择一类 pod 的输出，一般都是同类的 pod 数量非常多，我们会使用这个选项来追踪错误日志。 kubectl logs -f -l name=node-exporter -n kube-monitor --since=0s: Only return logs newer than a relative duration like 5s, 2m, or 3h. Defaults to all logs. Only one of since-time / since may be used. 这个可以看一下最近时间的日志，比如我们看 10 秒之内的日志。 kubectl logs -f -l name=node-exporter -n kube-monitor --since=10s --since-time='': Only return logs after a specific date (RFC3339). Defaults to all logs. Only one of since-time since may be used. 指定时间，但是格式是 ‘2020-02-25T14:33:33Z’，比如 kubectl logs -f -l name=node-exporter -n kube-monitor --since-time='2020-02-25T14:33:33Z' ","date":"2020-07-10","objectID":"/cka2.kubectl-logs/:2:0","tags":["容器(🚢)"],"title":"CKA(2.kubectl logs)","uri":"/cka2.kubectl-logs/"},{"categories":["CKA"],"content":"答案 kubectl logs foobar | grep error \u003e /logs ","date":"2020-07-10","objectID":"/cka2.kubectl-logs/:3:0","tags":["容器(🚢)"],"title":"CKA(2.kubectl logs)","uri":"/cka2.kubectl-logs/"},{"categories":["CKA"],"content":"题目 使用 name 排序列出所有的 PV，把输出内容存储到/opt/文件中 使用 kubectl own 对输出进行排序，并且不再进一步操作它 ","date":"2020-07-09","objectID":"/cka1.kubectl-get/:1:0","tags":["容器(🚢)"],"title":"CKA(1.kubectl get)","uri":"/cka1.kubectl-get/"},{"categories":["CKA"],"content":"解题 kubectl 是用来管理 k8s 的命令行工具之一，他主要是调用 KUBECONFIG 文件，并且加载其中的信息，向 kube-apiserver 发起请求。 一般格式 kubectl [command] [type] [name] [tags] kubectl controls the Kubernetes cluster manager. Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/ Basic Commands (Beginner): create Create a resource from a file or from stdin. expose Take a replication controller, service, deployment or pod and expose it as a new Kubernetes Service run Run a particular image on the cluster set Set specific features on objects Basic Commands (Intermediate): explain Documentation of resources get Display one or many resources edit Edit a resource on the server delete Delete resources by filenames, stdin, resources and names, or by resources and label selector Deploy Commands: rollout Manage the rollout of a resource scale Set a new size for a Deployment, ReplicaSet or Replication Controller autoscale Auto-scale a Deployment, ReplicaSet, or ReplicationController Cluster Management Commands: certificate Modify certificate resources. cluster-info Display cluster info top Display Resource (CPU/Memory/Storage) usage. cordon Mark node as unschedulable uncordon Mark node as schedulable drain Drain node in preparation for maintenance taint Update the taints on one or more nodes Troubleshooting and Debugging Commands: describe Show details of a specific resource or group of resources logs Print the logs for a container in a pod attach Attach to a running container exec Execute a command in a container port-forward Forward one or more local ports to a pod proxy Run a proxy to the Kubernetes API server cp Copy files and directories to and from containers. auth Inspect authorization Advanced Commands: diff Diff live version against would-be applied version apply Apply a configuration to a resource by filename or stdin patch Update field(s) of a resource using strategic merge patch [type]是指资源的类型，比如 pod，service，deployment kubectl get pods kubectl get deploy 需要注意的是，如果不加[name]选项，就是 get 所有的，而 pods 和 pod 目前的意思是一样的。 一个使用 kubeamd 新创建的集群，刚刚创建完成的时候，会有两个 namespaces，一个是 kube-system，用来存放 kube-apiserver 等系统用到的 pod，一个是 default，作为默认名称空间，如果创建资源的时候不指定名称空间，都会在这个空间里面存放。 root@shein-mointor-lab-01:~# kubectl get pod NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 2d1h root@shein-mointor-lab-01:~# kubectl get pod -n kube-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-76d4774d89-6tg9v 1/1 Running 2 38d calico-node-65tsz 1/1 Running 1 38d calico-node-gzh5l 1/1 Running 2 38d coredns-7ff77c879f-ql8dh 1/1 Running 2 38d coredns-7ff77c879f-zp8ms 1/1 Running 2 38d eip-nfs-kube-monitor-5f98475889-5tv7v 1/1 Running 2 3d12h eip-nfs-kube-ops-554dbf6855-wwll7 1/1 Running 0 2d11h etcd-shein-mointor-lab-01 1/1 Running 3 38d kube-apiserver-shein-mointor-lab-01 1/1 Running 2 38d kube-controller-manager-shein-mointor-lab-01 1/1 Running 2 38d kube-proxy-mpbdh 1/1 Running 2 38d kube-proxy-swj5c 1/1 Running 1 38d kube-scheduler-shein-mointor-lab-01 1/1 Running 3 38d kuboard-5454b89cb9-bz4s7 1/1 Running 0 25d metrics-server-7f96bbcc66-zr276 1/1 Running 2 3d12h root@shein-mointor-lab-01:~# [flags]选项也是琳琅满目，可以使用 kubectl get -h 来列出所有的选项，我们来对常用的进行说明。 root@shein-mointor-lab-01:~# kubectl get -h Display one or many resources Prints a table of the most important information about the specified resources. You can filter the list using a label selector and the --selector flag. If the desired resource type is namespaced you will only see results in your current namespace unless you pass --all-namespaces. Uninitialized objects are not shown unless --include-uninitialized is passed. By specifying the output as 'template' and providing a Go template as the value of the --template flag, you can filter the attributes of the fetched resources. Use \"kubectl api-resources\" for a complete list of supported resources. Examples: # List all pods in ps output format. kubectl get pods # List all pods in ps output format with more information (such as node name). kubectl get pods -o wide # List a sing","date":"2020-07-09","objectID":"/cka1.kubectl-get/:2:0","tags":["容器(🚢)"],"title":"CKA(1.kubectl get)","uri":"/cka1.kubectl-get/"},{"categories":["CKA"],"content":"答案 root@shein-mointor-lab-01:~# kubectl get pv --sort-by=.metadata.name NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE nfs-pv-kube-monitor 100Gi RWX Retain Bound kube-system/nfs-pvc-kube-monitor nfs-storageclass-provisioner 6d10h nfs-pv-kube-ops 100Gi RWX Retain Bound kube-system/nfs-pvc-kube-ops nfs-storageclass-provisioner 2d12h pvc-40cb9bc4-c533-4851-885e-7bc501474254 20Gi RWX Retain Bound kube-ops/opspvc kube-ops 2d12h pvc-d77b1164-2edd-4025-b691-8907db70cdaf 20Gi RWX Delete Bound kube-monitor/monitor kube-monitor 6d10h ","date":"2020-07-09","objectID":"/cka1.kubectl-get/:3:0","tags":["容器(🚢)"],"title":"CKA(1.kubectl get)","uri":"/cka1.kubectl-get/"},{"categories":["blog"],"content":"背景 在将hexo迁移到hugo后我就开始折腾博客搜索了，下面的配置正对loveit主题配置 ","date":"2020-06-06","objectID":"/hugo%E4%BD%BF%E7%94%A8algolia%E6%90%9C%E7%B4%A2/:1:0","tags":["hugo","hexo"],"title":"Hugo使用algolia搜索","uri":"/hugo%E4%BD%BF%E7%94%A8algolia%E6%90%9C%E7%B4%A2/"},{"categories":["blog"],"content":"开启algolia搜索 在config.toml中添加下面字段，xxxxx是必填，你可以参考loveit主题中的config.toml # 搜索配置 [languages.zh-cn.params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"algolia\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [languages.zh-cn.params.search.algolia] # algolia注册的索引名称 index = \"xxxxx\" # 在你注册完成后，点击API Keys就能看见下面的参数 appID = \"xxxxx\" searchKey = \"xxxxx\" ","date":"2020-06-06","objectID":"/hugo%E4%BD%BF%E7%94%A8algolia%E6%90%9C%E7%B4%A2/:2:0","tags":["hugo","hexo"],"title":"Hugo使用algolia搜索","uri":"/hugo%E4%BD%BF%E7%94%A8algolia%E6%90%9C%E7%B4%A2/"},{"categories":["blog"],"content":"自动提交索引到algolia 又又用到了npm,好在集成到travis中眼不见为净。 在config.toml同级目录下运行npm init，一路回车即可。 修改npm int生成的package.json添加下面字段 \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" \u0026\u0026 exit 1\", \"algolia\": \"atomic-algolia\" }, 在config.toml同级目录添加.env文件并添加下面字段 ❯ cat .env ALGOLIA_APP_ID=U9QMQ70DKL ALGOLIA_INDEX_NAME=gaojila.github.io ALGOLIA_INDEX_FILE=public/index.json 修改.travis.yml文件如下 language:gogo:- \"1.8\"# 指定Golang 1.8install:# 安装最新的hugo- wget https://github.com/gohugoio/hugo/releases/download/v0.71.1/hugo_0.71.1_Linux-64bit.deb- sudo dpkg -i hugo*.deb# 安装搜索插件- npm install atomic-algolia --save-devscript:# 运行hugo命令- hugo# 生成索引命令- echo \"ALGOLIA_ADMIN_KEY=$ALGOLIA_ADMIN_KEY\" \u003e\u003e .env- npm run algoliaafter_script:# 部署- cd ./public- git init- git config user.name \"[gaojila]\"- git config user.email \"[redgaojila@gmail.com]\"- git add .- git commit -m \"Update Blog By TravisCI With Build $TRAVIS_BUILD_NUMBER\"# Github Pages- git push --force --quiet \"https://$GITHUB_TOKEN@${GH_REF}\" master:master# Github Pages- git push --quiet \"https://$GITHUB_TOKEN@${GH_REF}\" master:master --tagsenv:global:# Github Pages- GH_REF:\"github.com/gaojila/gaojila.github.io\"deploy:provider:pages# 重要，指定这是一份github pages的部署配置skip-cleanup:true# 重要，不能省略local-dir:public# 静态站点文件所在目录# target-branch: master # 要将静态站点文件发布到哪个分支github-token:$GITHUB_TOKEN# 重要，$GITHUB_TOKEN是变量，需要在GitHub上申请、再到配置到Travis# fqdn: # 如果是自定义域名，此处要填keep-history:true# 是否保持target-branch分支的提交记录on:branch:master# 博客源码的分支 在travis中添加变量$ALGOLIA_ADMIN_KEY ","date":"2020-06-06","objectID":"/hugo%E4%BD%BF%E7%94%A8algolia%E6%90%9C%E7%B4%A2/:3:0","tags":["hugo","hexo"],"title":"Hugo使用algolia搜索","uri":"/hugo%E4%BD%BF%E7%94%A8algolia%E6%90%9C%E7%B4%A2/"},{"categories":["blog"],"content":"参考链接 aligolia的其他配置可以看下面的链接 dreamsafari.info nashome.cn ","date":"2020-06-06","objectID":"/hugo%E4%BD%BF%E7%94%A8algolia%E6%90%9C%E7%B4%A2/:4:0","tags":["hugo","hexo"],"title":"Hugo使用algolia搜索","uri":"/hugo%E4%BD%BF%E7%94%A8algolia%E6%90%9C%E7%B4%A2/"},{"categories":["blog"],"content":"背景 从hexo迁移到hugo后，发布博客开始变的繁琐，没有hexo -d这样的快捷部署，但是好在有travis这样的免费CI平台，在使用travis来部署博客的确快捷了很多，只需要发布源码即可。 ","date":"2020-06-05","objectID":"/hugo%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83/:1:0","tags":["hugo","hexo"],"title":"Hugo使用travis自动发布","uri":"/hugo%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83/"},{"categories":["blog"],"content":"Github获取token 记下 Token 的值 (一定要记下来，因为离开这个页面之后就没有机会再次查看了) ","date":"2020-06-05","objectID":"/hugo%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83/:2:0","tags":["hugo","hexo"],"title":"Hugo使用travis自动发布","uri":"/hugo%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83/"},{"categories":["blog"],"content":"设置Travis CI 使用github帐号注册一个travis帐号，登录在hugo仓库上打上，然后再点击setting然后填写 Environment Variables。 Name 填写： GITHUB_TOKEN Value 填写：刚刚在 GitHub 申请到的 Token 的值 点击add ","date":"2020-06-05","objectID":"/hugo%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83/:3:0","tags":["hugo","hexo"],"title":"Hugo使用travis自动发布","uri":"/hugo%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83/"},{"categories":["blog"],"content":"编写.trabis.yml language:gogo:- \"1.8\"# 指定Golang 1.8install:# 安装最新的hugo- wget https://github.com/gohugoio/hugo/releases/download/v0.71.1/hugo_0.71.1_Linux-64bit.deb- sudo dpkg -i hugo*.debscript:# 运行hugo命令- hugoafter_script:# 部署- cd ./public- git init- git config user.name \"[gaojila]\"- git config user.email \"[redgaojila@gmail.com]\"- git add .- git commit -m \"Update Blog By TravisCI With Build $TRAVIS_BUILD_NUMBER\"# Github Pages- git push --force --quiet \"https://$GITHUB_TOKEN@${GH_REF}\" master:master# Github Pages- git push --quiet \"https://$GITHUB_TOKEN@${GH_REF}\" master:master --tagsenv:global:# Github Pages- GH_REF:\"github.com/gaojila/gaojila.github.io\"deploy:provider:pages# 重要，指定这是一份github pages的部署配置skip-cleanup:true# 重要，不能省略local-dir:public# 静态站点文件所在目录# target-branch: master # 要将静态站点文件发布到哪个分支github-token:$GITHUB_TOKEN# 重要，$GITHUB_TOKEN是变量，需要在GitHub上申请、再到配置到Travis# fqdn: # 如果是自定义域名，此处要填keep-history:true# 是否保持target-branch分支的提交记录on:branch:master# 博客源码的分支 将上面的配置文件按照你的实际情况更改。 然后将代码提交到 hugo 仓库 里。等个一两分钟，就可以在 Travis CI 上查看部署情况了 绿色 代表部署成功 黄色代表正在部署 红色 代表部署失败 灰色 代表部署被取消 ","date":"2020-06-05","objectID":"/hugo%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83/:4:0","tags":["hugo","hexo"],"title":"Hugo使用travis自动发布","uri":"/hugo%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83/"},{"categories":["blog"],"content":"相关文章 使用 Travis CI 自动部署 Hugo 博客 ","date":"2020-06-05","objectID":"/hugo%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83/:5:0","tags":["hugo","hexo"],"title":"Hugo使用travis自动发布","uri":"/hugo%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83/"},{"categories":["blog"],"content":"迁移日志 ","date":"2020-06-05","objectID":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/:0:0","tags":["hugo","hexo"],"title":"Hexo迁移日志","uri":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/"},{"categories":["blog"],"content":"背景 在某个清晨，心血来潮想写个文档，在我使用hexo生成文档时发现我的 hexo 已经坏了，由于我使用的是 archlinux，我每天都有升级的习惯，奶奶的 hexo 每次都要为包操心。 ","date":"2020-06-05","objectID":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/:1:0","tags":["hugo","hexo"],"title":"Hexo迁移日志","uri":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/"},{"categories":["blog"],"content":"方法 方法还是比较简单的，只需要更改hexo的日期格式和toml格式的标签和分类就行，具体网上的教程已经很多了就不赘述了。 ","date":"2020-06-05","objectID":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/:2:0","tags":["hugo","hexo"],"title":"Hexo迁移日志","uri":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/"},{"categories":["blog"],"content":"对比 ","date":"2020-06-05","objectID":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/:3:0","tags":["hugo","hexo"],"title":"Hexo迁移日志","uri":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/"},{"categories":["blog"],"content":"优点 由于hugo是go语言编写，对比hexo提升了几十倍的编译速度。 再也不需要维护那么的 npm 包了，迁移变的更简单。 ","date":"2020-06-05","objectID":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/:3:1","tags":["hugo","hexo"],"title":"Hexo迁移日志","uri":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/"},{"categories":["blog"],"content":"缺点 对比hexo主题实在是太丑了，我再也没有花里胡哨的博客了。 我暂时也没有找到 hugo 嵌入看板娘的方法，我不想去维护 npm 包了。 ","date":"2020-06-05","objectID":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/:3:2","tags":["hugo","hexo"],"title":"Hexo迁移日志","uri":"/%E5%B0%86hexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo/"},{"categories":["linux(🐧)"],"content":"Centos7 升级最新内核 ","date":"2020-06-02","objectID":"/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/:0:0","tags":["内核升级"],"title":"Centos7升级内核至最新","uri":"/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/"},{"categories":["linux(🐧)"],"content":"应用背景 最近在接触 k8s，其对内核版本要求较高，centos7.x 默认内核版本为 3.10.0-xxx，只能满足其最低要求，故借此机会记录一下升级内核的操作步骤。 ","date":"2020-06-02","objectID":"/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/:1:0","tags":["内核升级"],"title":"Centos7升级内核至最新","uri":"/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/"},{"categories":["linux(🐧)"],"content":"操作步骤 ","date":"2020-06-02","objectID":"/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/:2:0","tags":["内核升级"],"title":"Centos7升级内核至最新","uri":"/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/"},{"categories":["linux(🐧)"],"content":"小版本升级 查看当前可升级版本 [root@server-1 ~]# yum list kernel Installed Packages kernel.x86_64 3.10.0-957.el7 @anaconda Available Packages kernel.x86_64 3.10.0-957.5.1.el7 updates 升级 [root@server-1 ~]# yum update kernel -y 重启并检查 [root@server-1 ~]# reboot [root@server-1 ~]# uname -r ","date":"2020-06-02","objectID":"/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/:2:1","tags":["内核升级"],"title":"Centos7升级内核至最新","uri":"/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/"},{"categories":["linux(🐧)"],"content":"大版本升级 载入公钥 [root@server-1 ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org 升级安装 ELRepo [root@server-1 ~]# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm 载入 elrepo-kernel 元数据 [root@server-1 ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel repolist 查看可用的 rpm 包 [root@server-1 ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel list kernel* Installed Packages kernel.x86_64 3.10.0-957.el7 @anaconda kernel.x86_64 3.10.0-957.5.1.el7 @updates kernel-tools.x86_64 3.10.0-957.el7 @anaconda kernel-tools-libs.x86_64 3.10.0-957.el7 @anaconda Available Packages kernel-lt.x86_64 4.4.176-1.el7.elrepo elrepo-kernel kernel-lt-devel.x86_64 4.4.176-1.el7.elrepo elrepo-kernel kernel-lt-doc.noarch 4.4.176-1.el7.elrepo elrepo-kernel kernel-lt-headers.x86_64 4.4.176-1.el7.elrepo elrepo-kernel kernel-lt-tools.x86_64 4.4.176-1.el7.elrepo elrepo-kernel kernel-lt-tools-libs.x86_64 4.4.176-1.el7.elrepo elrepo-kernel kernel-lt-tools-libs-devel.x86_64 4.4.176-1.el7.elrepo elrepo-kernel kernel-ml.x86_64 4.20.12-1.el7.elrepo elrepo-kernel　// 安装目标版本 kernel-ml-devel.x86_64 4.20.12-1.el7.elrepo elrepo-kernel kernel-ml-doc.noarch 4.20.12-1.el7.elrepo elrepo-kernel kernel-ml-headers.x86_64 4.20.12-1.el7.elrepo elrepo-kernel kernel-ml-tools.x86_64 4.20.12-1.el7.elrepo elrepo-kernel kernel-ml-tools-libs.x86_64 4.20.12-1.el7.elrepo elrepo-kernel kernel-ml-tools-libs-devel.x86_64 4.20.12-1.el7.elrepo elrepo-kernel 说明： lt ：long term support，长期支持版本； ml：mainline，主线版本； 安装最新版本的 kernel [root@server-1 ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel install kernel-ml.x86_64 -y 删除旧版本工具包 [root@server-1 ~]# yum remove kernel-tools-libs.x86_64 kernel-tools.x86_64 -y 安装新版本工具包 [root@server-1 ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel install kernel-ml-tools.x86_64 -y 查看内核插入顺序 [root@server-1 ~]# awk -F \\' '$1==\"menuentry \" {print i++ \" : \" $2}' /etc/grub2.cfg 0 : CentOS Linux (4.20.12-1.el7.elrepo.x86_64) 7 (Core) 1 : CentOS Linux (3.10.0-957.5.1.el7.x86_64) 7 (Core) 2 : CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core) 3 : CentOS Linux (0-rescue-ca0f6fb3c5f24478abc0a2e275281d7a) 7 (Core) 说明：默认新内核是从头插入，默认启动顺序也是从 0 开始（当前顺序还未生效），或者使用： [root@server-17 ~]# grep \"^menuentry\" /boot/grub2/grub.cfg | cut -d \"'\" -f2 CentOS Linux (4.20.12-1.el7.elrepo.x86_64) 7 (Core) CentOS Linux (3.10.0-957.5.1.el7.x86_64) 7 (Core) CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core) CentOS Linux (0-rescue-ca0f6fb3c5f24478abc0a2e275281d7a) 7 (Core) 其中文件 /etc/grub2.cfg 和 /boot/grub2/grub.cfg 内容一致。 查看当前实际启动顺序 [root@server-1 ~]# grub2-editenv list saved_entry=CentOS Linux (3.10.0-957.5.1.el7.x86_64) 7 (Core) 设置默认启动 [root@server-1 ~]# grub2-set-default 'CentOS Linux (4.20.12-1.el7.elrepo.x86_64) 7 (Core)' [root@server-1 ~]# grub2-editenv list saved_entry=CentOS Linux (4.20.12-1.el7.elrepo.x86_64) 7 (Core) 或者直接设置数值 [root@server-1 ~]# grub2-set-default 0　// 0代表当前第一行，也就是上面的4.20.12版本那一行内容 [root@server-1 ~]# grub2-editenv list saved_entry=0 重启并检查 [root@server-1 ~]# reboot [root@server-1 ~]# uname -r ","date":"2020-06-02","objectID":"/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/:2:2","tags":["内核升级"],"title":"Centos7升级内核至最新","uri":"/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/"},{"categories":["容器(🚢)"],"content":"Service 的类型 ClusterIP： 默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟 IP。 NodePort： 在 ClusterIP 的基础上为 service 在每台机器撒谎那个绑定一个端口，这样就可通过 NodePort 来访问服务。 LoadBalancer： 在 NodePort 的基础上，借助 cloud provider 创建一个外部负载均衡器，并将请求转发到 NodePort。 ExternalName： 把集群外部的服务引入到集群内部来，在集群内部直接使用，没有任何类型代理被创建。 ","date":"2020-04-23","objectID":"/k8s%E6%9C%8D%E5%8A%A1/:1:0","tags":["service(ClusterIP,NodePort,LoadBalancer,ExternalName)"],"title":"k8s-service","uri":"/k8s%E6%9C%8D%E5%8A%A1/"},{"categories":["容器(🚢)"],"content":"Job Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束 特殊说明： spec.template 格式同 Pod RestartPolicy 仅支持 Never 或 OnFailure 单个 Pod 时，默认 Pod 成功运行后 Job 即结束 .spec.completions：标志 Job 结束需要成功运行的 Pod 个数，默认为 1 .spec.parallelism：标志并运行的 Pod 的个数，默认为 1 .spec.activeDeadlineSecond：标志失败 Pod 的重试最大时间，超过这个时间不会继续重试 For Expamle kind:Jobmetadata:name:pispec:template:metadata:name:pispec:containers:- name:piimage:perlcommand:[\"perl\",\"-Mbignum=bpi\",\"-wle\",\"print bpi(2000)\"]restartPolicy:Never ","date":"2020-04-21","objectID":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8jobcronjob/:1:0","tags":["资源控制器(Job,CronJob)"],"title":"k8s资源控制器JobCronJob","uri":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8jobcronjob/"},{"categories":["容器(🚢)"],"content":"CronJob CronJob 管理基于时间的 Job，即： 在给定时间点只运行一次 周期性地在个体定时间点运行 典型用法如下所示： 在给定的时间点调度 Job 运行 创建周期性运行的 Job，例如：数据库的备份、发送邮件 特殊说明： .spec.schedule：调度，必须字段，指定任务运行周期，格式同 linux Cron。 .spec.jobTemplate：Job 模板，必须字段，指定需要运行的任务，格式同 Job。 .spec.startingDeadlineSeconds：启动 Job 的期限（秒级别），该字段是可选的，如果因为任何原因而错过卢被调度的时间，那么错过执行时间的 Job 将被认为是失败的，如果没有指定，则没有期限。 .spec.concurrencyPolicy：并发策略，该字段也是可选的，它指定卢如何处理被 CronJob 创建的 Job 的并发执行，只允许下面策略中的一种。 Allow（默认）：允许并发运行 Job。 Forbid：禁止并发运行，如果前一个还没有完成，则直接跳过下一个。 Replace：取消当前正在运行的 Job，用一个新的来替换。 注意：当前策略只能应用于同一个 CronJob 创建的 Job，如何存在多个 CronJob，他们创建的 Job 之间总是并发运行的。 .spec.suspend：挂起，该字段也是可选的，如果设为true，后续所有执行都会被挂起，它对已经开始执行的 Job 不起作用，默认值为false。 .spec.successfulJobHistoryLimit和.spec.failedJobsHistoryLimit：历史限制，可选字段，它们指定了可以保留多少完成和失败的 Job，默认情况下，它们分别设置 3 和 1，设置限制的值为 0，相关类型的 Job 完成后将不会被保留。 For Expamle apiVersion:batch/v1beta1kind:CronJobmetadata:name:hellospec:schedule:\"*/1 * * * *\"jobTemplate:spec:template:spec:containers:- name:helloimage:busyboxargs:- /bin/sh- -c- date; echo Hello from the Kubernetes clusterrestartPolicy:OnFailure ","date":"2020-04-21","objectID":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8jobcronjob/:2:0","tags":["资源控制器(Job,CronJob)"],"title":"k8s资源控制器JobCronJob","uri":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8jobcronjob/"},{"categories":["容器(🚢)"],"content":"什么是 DaemonSet DaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本，当有 Node 加入集群时，也会为他们新增一个 Pod，当有 Node 从集群移除时，这些 Pod 也会被回收，删除 DaemonSet 将会删除它所创建的所有 Pod。 使用 DaemonSet 的一些典型用法： 运行集群存储 daemon,例如在每个 Node 上运行glusterd、ceph。 在每个 Node 上运行日志收集 daemon，例如fluentd、logstash。 在每个 Node 上运行监控 daemon，例如Prometheus Node Exporter、colletcd、Datadog、New Relic、Ganglia、gmond。 For Expamle apiVersion:apps/v1kind:DaemonSetmetadata:name:daemonset-examplelabels:app:daemonsetspec:selector:matchLabels:name:daemonset-exampletemplate:metadata:labels:name:daemonset-examplespec:containers:- name:daemonset-exampleimage:wangyanglinux/myapp:v1 ","date":"2020-04-21","objectID":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8daemonset/:1:0","tags":["-资源控制器(DaemonSet)"],"title":"k8s资源控制器DaemonSet","uri":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8daemonset/"},{"categories":["容器(🚢)"],"content":"配置 readiness 和 liveness 探针 (参考 Jimmy Song 大佬的文章学习) Kubelet 使用 liveness probe（存活探针）来确定何时重启容器。例如，当应用程序处于运行状态但无法做进一步操作，liveness 探针将捕获到 deadlock，重启处于该状态下的容器，使应用程序在存在 bug 的情况下依然能够继续运行下去（谁的程序还没几个 bug 呢）。 Kubelet 使用 readiness probe（就绪探针）来确定容器是否已经就绪可以接受流量。只有当 Pod 中的容器都处于就绪状态时 kubelet 才会认定该 Pod 处于就绪状态。该信号的作用是控制哪些 Pod 应该作为 service 的后端。如果 Pod 处于非就绪状态，那么它们将会被从 service 的 load balancer 中移除。 ","date":"2020-04-19","objectID":"/k8s%E6%8E%A2%E9%92%88/:0:0","tags":["探针(readiness,liveness)"],"title":"k8s探针","uri":"/k8s%E6%8E%A2%E9%92%88/"},{"categories":["容器(🚢)"],"content":"liveness 探针 ","date":"2020-04-19","objectID":"/k8s%E6%8E%A2%E9%92%88/:1:0","tags":["探针(readiness,liveness)"],"title":"k8s探针","uri":"/k8s%E6%8E%A2%E9%92%88/"},{"categories":["容器(🚢)"],"content":"定义一个 liveness exec 许多长时间运行的应用程序最终会转换到 broken 状态，除非重新启动，否则无法恢复。Kubernetes 提供了 liveness probe 来检测和补救这种情况。 在本次练习将基于 busybox 镜像创建运行一个容器的 Pod。以下是 Pod 的配置文件 live-exec.yaml： apiVersion:v1kind:Podmetadata:name:liveness-exec-podnamespace:defaultspec:containers:- name:liveness-exec-containerimage:busyboximagePullPolicy:IfNotPresentcommand:[\"sh\",\"-c\",\"touch /tmp/live ; sleep 60 ; rm -rf /tmp/live ; sleep 3600\",]livenessProbe:exec:command:[\"test\",\"-e\",\"/tmp/live:\"]initialDelaySeconds:1periodSeconds:3 该配置文件给 Pod 配置了一个容器。periodSeconds 规定 kubelet 要每隔 3 秒执行一次 liveness probe。 initialDelaySeconds 告诉 kubelet 在第一次执行 probe 之前要的等待 1 秒钟。探针检测命令是在容器中执行 cat /tmp/live 命令。如果命令执行成功，将返回 0，kubelet 就会认为该容器是活着的并且很健康。如果返回非 0 值，kubelet 就会杀掉这个容器并重启它。 容器启动时，执行该命令： /bin/bash -c \"touch /tmp/live ; sleep 60 ; rm -rf /tmp/live ; sleep 3600\" 在容器生命的最初 60 秒内有一个 /tmp/live 文件，在这 60 秒内 cat /tmp/live 命令会返回一个成功的返回码。60 秒后， cat /tmp/live 将返回失败的返回码。 创建 pod： kubectl create -f live-exec.yml 60 秒后，查看 Pod 已经有重启： [root@kube-master01 liveness]# kubectl get pod liveness-exec-pod -w NAME READY STATUS RESTARTS AGE liveness-exec-pod 1/1 Running 2 91s ","date":"2020-04-19","objectID":"/k8s%E6%8E%A2%E9%92%88/:1:1","tags":["探针(readiness,liveness)"],"title":"k8s探针","uri":"/k8s%E6%8E%A2%E9%92%88/"},{"categories":["容器(🚢)"],"content":"定义一个 liveness httpGet 我们还可以使用 HTTP GET 请求作为 liveness probe。下面是一个基于 gcr.io/google_containers/liveness 镜像运行了一个容器的 Pod 的例子 http-liveness.yaml： apiVersion:v1kind:Podmetadata:name:liveness-httpget-podnamespace:defaultspec:containers:- name:liveness-httpget-containerimage:wangyanglinux/myapp:v1imagePullPolicy:IfNotPresentports:- name:httpcontainerPort:80livenessProbe:httpGet:port:80path:/index.htmlinitialDelaySeconds:1periodSeconds:3timeoutSeconds:10 ","date":"2020-04-19","objectID":"/k8s%E6%8E%A2%E9%92%88/:1:2","tags":["探针(readiness,liveness)"],"title":"k8s探针","uri":"/k8s%E6%8E%A2%E9%92%88/"},{"categories":["容器(🚢)"],"content":"定义一个 liveness tcpSocket 第三种 liveness probe 使用 TCP Socket。 使用此配置，kubelet 将尝试在指定端口上打开容器的套接字。 如果可以建立连接，容器被认为是健康的，如果不能就认为是失败的。 apiVersion:v1kind:Podmetadata:name:liveness-tcp-podnamespace:defaultspec:containers:- name:liveness-tcp-containerimage:wangyanglinux/myapp:v1imagePullPolicy:IfNotPresentports:- name:httpcontainerPort:80livenessProbe:tcpSocket:port:80initialDelaySeconds:1periodSeconds:3timeoutSeconds:10 ","date":"2020-04-19","objectID":"/k8s%E6%8E%A2%E9%92%88/:1:3","tags":["探针(readiness,liveness)"],"title":"k8s探针","uri":"/k8s%E6%8E%A2%E9%92%88/"},{"categories":["容器(🚢)"],"content":"使用命名端口 可以使用命名的 ContainerPort 作为 HTTP 或 TCP liveness 检查： ports:- name:liveness-portcontainerPort:8080hostPort:8080livenessProbe:httpGet:path:/healthzport:liveness-port ","date":"2020-04-19","objectID":"/k8s%E6%8E%A2%E9%92%88/:1:4","tags":["探针(readiness,liveness)"],"title":"k8s探针","uri":"/k8s%E6%8E%A2%E9%92%88/"},{"categories":["容器(🚢)"],"content":"定义 readiness 探针 有时，应用程序暂时无法对外部流量提供服务。 例如，应用程序可能需要在启动期间加载大量数据或配置文件。 在这种情况下，你不想杀死应用程序，但你也不想发送请求。 Kubernetes 提供了 readiness probe 来检测和减轻这些情况。 Pod 中的容器可以报告自己还没有准备，不能处理 Kubernetes 服务发送过来的流量。 Readiness probe 的配置跟 liveness probe 很像。唯一的不同是使用 readinessProbe 而不是 livenessProbe。 apiVersion:v1kind:Podmetadata:name:readiness-httpget-podnamespace:defaultspec:containers:- name:readiness-httpget-containerimage:wangyanglinux/myapp:v1imagePullPolicy:IfNotPresentreadinessProbe:httpGet:port:80path:/index1.htmlinitialDelaySeconds:1periodSeconds:3 Readiness probe 的 HTTP 和 TCP 的探测器配置跟 liveness probe 一样。 Readiness 和 livenss probe 可以并行用于同一容器。 使用两者可以确保流量无法到达未准备好的容器，并且容器在失败时重新启动。 ","date":"2020-04-19","objectID":"/k8s%E6%8E%A2%E9%92%88/:2:0","tags":["探针(readiness,liveness)"],"title":"k8s探针","uri":"/k8s%E6%8E%A2%E9%92%88/"},{"categories":["容器(🚢)"],"content":"配置 Probe Probe 中有很多精确和详细的配置，通过它们你能准确的控制 liveness 和 readiness 检查： initialDelaySeconds：容器启动后第一次执行探测是需要等待多少秒。 periodSeconds：执行探测的频率。默认是 10 秒，最小 1 秒。 timeoutSeconds：探测超时时间。默认 1 秒，最小 1 秒。 successThreshold：探测失败后，最少连续探测成功多少次才被认定为成功。默认是 1。对于 liveness 必须是 1。最小值是 1。 failureThreshold：探测成功后，最少连续探测失败多少次才被认定为失败。默认是 3。最小值是 1。 HTTP probe 中可以给 httpGet 设置其他配置项： host：连接的主机名，默认连接到 pod 的 IP。你可能想在 http header 中设置\"Host\"而不是使用 IP。 scheme：连接使用的 schema，默认 HTTP。 path: 访问的 HTTP server 的 path。 httpHeaders：自定义请求的 header。HTTP 运行重复的 header。 port：访问的容器的端口名字或者端口号。端口号必须介于 1 和 65535 之间。 对于 HTTP 探测器，kubelet 向指定的路径和端口发送 HTTP 请求以执行检查。 Kubelet 将 probe 发送到容器的 IP 地址，除非地址被 httpGet 中的可选 host 字段覆盖。 在大多数情况下，你不想设置主机字段。 有一种情况下你可以设置它。 假设容器在 127.0.0.1 上侦听，并且 Pod 的 hostNetwork 字段为 true。 然后，在 httpGet 下的 host 应该设置为 127.0.0.1。 如果你的 pod 依赖于虚拟主机，这可能是更常见的情况，你不应该是用 host，而是应该在 httpHeaders 中设置 Host 头。 ","date":"2020-04-19","objectID":"/k8s%E6%8E%A2%E9%92%88/:3:0","tags":["探针(readiness,liveness)"],"title":"k8s探针","uri":"/k8s%E6%8E%A2%E9%92%88/"},{"categories":["linux(🐧)"],"content":"禁用 root 密码登录 禁用密码登录 RSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys systemctl restart sshd ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/:1:0","tags":["safe"],"title":"linux系统安全设置","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/"},{"categories":["linux(🐧)"],"content":"配置会话自动登出 修改.bashrc 或者.profile echo \"TMOUT=90\"\u003e\u003e.bashrc source .bashrc 修改 ssh 配置 ClientAliveInterval 90 ClientAliveCountMax 2 systemctl restart sshd ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/:2:0","tags":["safe"],"title":"linux系统安全设置","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/"},{"categories":["linux(🐧)"],"content":"设置帐号锁定次数，锁定时间 ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/:3:0","tags":["safe"],"title":"linux系统安全设置","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/"},{"categories":["linux(🐧)"],"content":"Ulimit 配置 linux 操作系统默认只能打开 1024 个文件，打开的文件超过这个数发现程序会有“too many open files”的错误，1024 对于大数据系统来说显然是不够的，如果不设置，基本上整个大数据系统是“不可用的”，根本不能用于生产环境。 配置方法如下： echo \"* soft nofile 128000\" \u003e\u003e /etc/security/limits.conf echo \"* hard nofile 128000\" \u003e\u003e /etc/security/limits.conf echo \"* soft nproc 128000\" \u003e\u003e /etc/security/limits.conf echo \"* hard nproc 128000\" \u003e\u003e /etc/security/limits.conf 【修改建议：强烈建议修改，无影响】 ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/:1:0","tags":["parameter"],"title":"linux系统常用的参数优化","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"},{"categories":["linux(🐧)"],"content":"swap 分区配置 让系统尽量不使用 swap，如果按照默认配置为 60，则容易导致内存还够的情况下使用 swap，有可能导致 jvm 的 gc 回收处于 swap 的内存，造成一系列超时问题。 不是不能再使用 swap，只是尽量不使用 swap。 echo \"vm.swappiness=1\" \u003e\u003e /etc/sysctl.conf sysctl -p sysctl -a|grep swappiness 【修改建议：强烈建议修改，无影响】 ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/:2:0","tags":["parameter"],"title":"linux系统常用的参数优化","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"},{"categories":["linux(🐧)"],"content":"内存映射数量限制问题 如果 solr 内存映射过多，会超出系统限制的个数 65530，导致 solr 问题。 vi /etc/sysctl.conf vm.max_map_count=262144 sysctl -p 【修改建议：强烈建议修改，无影响】 ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/:3:0","tags":["parameter"],"title":"linux系统常用的参数优化","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"},{"categories":["linux(🐧)"],"content":"监听队列大小 tcp 连接的时候 listen 监听队列的大小默认为 128. echo \" net.core.somaxconn = 32768 \" \u003e\u003e /etc/sysctl.conf sysctl -p sysctl -a|grep somaxconn 【修改建议： 一般，无影响】 ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/:4:0","tags":["parameter"],"title":"linux系统常用的参数优化","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"},{"categories":["linux(🐧)"],"content":"透明大页问题 在 centos7 的系统版本中，透明大页这种本来为提高性能的手段，会系统负载高的时候，造成系统反复重启，所以建议关闭。 1）查看是否启用： [root@localhost ~]# cat /sys/kernel/mm/transparent_hugepage/enabled [always] madvise never [always]为启动。 2）停止方法： 1、第一种方法：对于centos7来说：【临时修改可以直接用下面两条命令】 更改：/etc/rc.d/rc.local echo never \u003e /sys/kernel/mm/transparent_hugepage/enabled echo never \u003e /sys/kernel/mm/transparent_hugepage/defrag 修改权限： chmod +x /etc/rc.d/rc.local 2、第二种方法： 修改 /etc/grub.conf 重启后生效。 添加：transparent_hugepage=never 举个例子： For example: title Oracle Linux Server (2.6.32-300.25.1.el6uek.x86_64) root (hd0,0) kernel /vmlinuz-2.6.32-300.25.1.el6uek.x86_64 ro root=LABEL=/ transparent_hugepage=never initrd /initramfs-2.6.32-300.25.1.el6uek.x86_64.img 【修改建议：建议修改，对系统性能有点影响】 ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/:5:0","tags":["parameter"],"title":"linux系统常用的参数优化","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"},{"categories":["linux(🐧)"],"content":"内存分配策略 overcommit_memory [root@localhost ~]# cat /proc/sys/vm/overcommit_memory 0 内核参数overcommit_memory 它是 内存分配策略 可选值：0、1、2。 0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 2， 表示内核允许分配超过所有物理内存和交换空间总和的内存 【建议设置为0，目前环境为0 不用修改】 ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/:6:0","tags":["parameter"],"title":"linux系统常用的参数优化","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"},{"categories":["linux(🐧)"],"content":"NUMA 参数问题 numa 为一种架构模式，就是内存和 cpu 组绑定，提升总线通信带宽。配置不当容易造成明明内存很多，但是却在使用 swap 问题。 1、查看是否开启NUMA 通过命令： grep -i numa /var/log/dmesg 如果输出:No NUMA configuration found 则没有开启，否则是开启了NUMA 我们主机显示： [ 3.175740] pci_bus 0000:00: on NUMA node 0 [ 3.180438] pci_bus 0000:10: on NUMA node 1 [ 3.185192] pci_bus 0000:20: on NUMA node 2 [ 3.189191] pci_bus 0000:30: on NUMA node 3 [ 3.191694] pci_bus 0000:40: on NUMA node 4 [ 3.194062] pci_bus 0000:50: on NUMA node 5 [ 3.198240] pci_bus 0000:60: on NUMA node 6 [ 3.200434] pci_bus 0000:70: on NUMA node 7 表明开启了NUMA。 2、查看分配策略 cat /proc/sys/vm/zone_reclaim_mode 目前环境为0 ，建议为0 不用修改。 当某个节点可用内存不足时： 1、如果为0的话，那么系统会倾向于从其他节点分配内存 2、如果为1的话，那么系统会倾向于从本地节点回收Cache内存多数时候 ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/:7:0","tags":["parameter"],"title":"linux系统常用的参数优化","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"},{"categories":["linux(🐧)"],"content":"时钟同步 使用 chronyc 进行时钟同步 ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/:8:0","tags":["parameter"],"title":"linux系统常用的参数优化","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"},{"categories":["linux(🐧)"],"content":"关闭 SELINUX 1）查看： /etc/selinux/config 2）修改 setenforce 0 sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/:9:0","tags":["parameter"],"title":"linux系统常用的参数优化","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"},{"categories":["linux(🐧)"],"content":"禁用 IPV6 echo -e \"NETWORKING_IPV6=no\" \u003e\u003e /etc/sysconfig/network echo -e \"alias net-pf-10 off\\noptions ipv6 disable=1\" \u003e /etc/modprobe.d/disable_ipv6.conf systemctl restart network ","date":"2020-03-15","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/:10:0","tags":["parameter"],"title":"linux系统常用的参数优化","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"},{"categories":null,"content":"📱 联系方式 电话：18762400277 邮件：redgaojila@gmail.com ","date":"2020-03-02","objectID":"/about/:1:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"👨 个人信息 男，1994 年出生，安徽六安 求职意向：Linux 运维工程师 工作经验：4 年 个人博客：https://gaojila.github.io/ ","date":"2020-03-02","objectID":"/about/:2:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"🏫 教育经历 学士，苏州大学文正学院，计算机科学与技术，2013.9~2017.7 ","date":"2020-03-02","objectID":"/about/:3:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"👷 工作经历 「2017.6~2020.4」南京金斯瑞生物科技科技有限公司，信息部，系统运维工程师。 「2020.4~至今」南京希音电子商务有限公司，产品研发部，系统运维工程师。 ","date":"2020-03-02","objectID":"/about/:4:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"📖 项目经历 Greenplum 迁移项目 结合 Backuppc 实现分布式数据库 Greenplum 的自动备份，备份工具选择官方的 gpbackup, 在一月初由于不可抗力的因素（存储故障）Greenplum 宕机，后使用 gprestore 迁移成功。 Zabbix 自动化监控平台 结合 Netdata，Grafana 实现监控可视化展板，日常自动化监控开发实现特殊监控需求。 Nexus 开源 maven 私有仓库 老的 Nexus 在一次季度维护中，无法启动，后使用 Docker 搭建 Nexus 私有仓库。 Ansible 管理工具 一些常用的安装配置版本管理化，可追溯资产变更，在初始化操作系统时使用 Ansible 减少运维人员工作负担(自动加入监控，自动加入堡垒机，自动加入备份)。 Jenkins Gitlab CI/CD 以往一些分散的业务系统使用 Pipeline script from SCM 模块 Groovy 脚本实现发布测试集中管理。 小项目开源工具部署 Docker 化 一些开源的项目，推进 Docker 快速部署，使用 Dockerfile 实现版本管理（营销邮件系统、Nexus、wordpress)。 Backuppc 自动化备份 使用 shell 开发结合 Backuppc 实现 Mysql（MEB）的自动化备份。 使用 shell 开发结合 Backuppc 实现 Greenplum（gpbackup）的自动化备份。 Kubernetes 容器监控 基于 Prometheus 实现 Kubernetes 下的应用监控，流量监控，组件监控。 Prometheus 监控设计 单节点Prometheus,实现按应用分组分为多个Prometheus节点，使用Thanos side car模式做高可用。 ","date":"2020-03-02","objectID":"/about/:5:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"🐧 技能清单 运维 ★★★★☆ Linux (Fedora,SuSe,Debain,Archlinux,Gentoo) ★★★☆☆ NBU、Backuppc ★★★☆☆ Nginx、Apache ★★★★☆ Zabbix、Grafana、Prometheus ★★☆☆☆ Mysql、Greenplum 开发 ★★★★☆ Bash、Python、Golang ★★★★☆ Jenkins、Gitlab、Ansible ★★☆☆☆ K8s、Docker ","date":"2020-03-02","objectID":"/about/:6:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"💓 致谢 我期待能与您一起共事，期待为您的企业添砖加瓦，期待与您一起探讨新技术，期待与您一起喝咖啡!!! ","date":"2020-03-02","objectID":"/about/:7:0","tags":null,"title":"","uri":"/about/"},{"categories":["Git"],"content":"Git 分布式版本管理系统 Git 命令清单 workspace: 工作区 Index/Stage: 暂存区 Repository: 仓库区(或本地仓库) Remote: 远程仓库 ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:0:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["Git"],"content":"新建代码库 # 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 细崽一个项目和它的整个代码历史 $ git clone [url] ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:1:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["Git"],"content":"配置 Git 的配置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 # 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name \"[name]\" $ git config [--global] user.email \"[email address]\" ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:2:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["Git"],"content":"增加/删除文件 # 添加指定文件到暂存区 $ git add [file1] [file2] # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每一个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并将这次删除放入暂存区 $ git rm [file1] [file2] # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:3:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["Git"],"content":"代码提交 # 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上一次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有的diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit,并包括指定文件的新变化 $ git commit --amend [file1] [file2] ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:4:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["Git"],"content":"分支 # 列出所有本地分支 $ git branch # 列出所有远程分支 $ git branch -r # 列出所有本地分支和远程分支 $ git branch -a # 新建一个分支，单依然停留在当前分支 $ git branch [branch-name] # 新建一个分支，并切换到该分支 $ git cleckout -b [branch] # 新建一个分支，并指向指定commit $ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区 $ git checkout [branch-name] # 切换到上一个分支 $ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支 $ git merge [branch] # 选择一个commit，合并近当前分支 $ git cherry-pick [commit] # 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:5:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["Git"],"content":"标签 # 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] ＃新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] ＃提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，并指向某个tag $ git checkout -b [branch] [tag] ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:6:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["Git"],"content":"查看信息 # 显示有变更的文件 $ git status # 显示当前分支的历史版本 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其”提交说明“必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去的5次提交 $ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码 $ git diff --short --shortstat \"@{0 day ago}\" # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] # 显示当前分支的最近几次提交 $ git reflog ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:7:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["Git"],"content":"远程同步 # 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:8:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["Git"],"content":"撤销 # 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区与工作区，与上一次commit保持一致,但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针未指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:9:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["Git"],"content":"其他 # 生成一个可供发布的压缩包 $ git archive ","date":"2020-02-17","objectID":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/:10:0","tags":["git使用总结"],"title":"git使用总结","uri":"/git%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"},{"categories":["容器(🚢)"],"content":"ReplicaSet ","date":"2020-02-12","objectID":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/:0:0","tags":["资源控制器(RS,deployment)"],"title":"k8s资源控制器","uri":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/"},{"categories":["容器(🚢)"],"content":"什么是 ReplicaSet？ ReplicaSet 是下一代复本控制器。ReplicaSet 和 Replication Controller 之间的唯一区别是现在的选择器支持。Replication Controller 只支持基于等式的 selector（env=dev 或 environment!=qa），但 ReplicaSet 还支持新的，基于集合的 selector（version in (v1.0, v2.0)或 env notin (dev, qa)）。在试用时官方推荐 ReplicaSet。 大多数 kubectl 支持 Replication Controller 的命令也支持 ReplicaSets。rolling-update 命令有一个例外 。如果您想要滚动更新功能，请考虑使用 Deployments。此外， rolling-update 命令是必须的，而 Deployments 是声明式的，因此我们建议通过 rollout 命令使用 Deployments。 虽然 ReplicaSets 可以独立使用，但是今天它主要被 Deployments 作为协调 pod 创建，删除和更新的机制。当您使用 Deployments 时，您不必担心管理他们创建的 ReplicaSets。Deployments 拥有并管理其 ReplicaSets。 ","date":"2020-02-12","objectID":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/:1:0","tags":["资源控制器(RS,deployment)"],"title":"k8s资源控制器","uri":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/"},{"categories":["容器(🚢)"],"content":"何时使用 ReplicaSet？ ReplicaSet 可确保指定数量的 pod“replicas”在任何设定的时间运行。然而，Deployments 是一个更高层次的概念，它管理 ReplicaSets，并提供对 pod 的声明性更新以及许多其他的功能。因此，我们建议您使用 Deployments 而不是直接使用 ReplicaSets，除非您需要自定义更新编排或根本不需要更新。 这实际上意味着您可能永远不需要操作 ReplicaSet 对象：直接使用 Deployments 并在规范部分定义应用程序。 ","date":"2020-02-12","objectID":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/:2:0","tags":["资源控制器(RS,deployment)"],"title":"k8s资源控制器","uri":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/"},{"categories":["容器(🚢)"],"content":"演示 建立 rs.yml 文档 apiVersion:apps/v1kind:ReplicaSetmetadata:name:frontendspec:replicas:3#有三个模板selector:#标签选择器matchLabels:tier:frontendtemplate:#模板metadata:labels:tier:frontendspec:containers:- name:myappimage:nginxenv:- name:GET_HOSTS_FROMvalue:dnsports:- containerPort:80 创建 pod kubectl create -f rs.yml 查看 rs [root@apiserver ~]# kubectl get rs NAME DESIRED CURRENT READY AGE frontend 3 3 3 21s 查看 pod [root@apiserver ~]# kubectl get pod NAME READY STATUS RESTARTS AGE frontend-87wtq 1/1 Running 0 23s frontend-r8kjt 1/1 Running 0 23s frontend-w7n98 1/1 Running 0 23s 查看 rs 标签 [root@apiserver ~]# kubectl get pod --show-labels NAME READY STATUS RESTARTS AGE LABELS frontend-87wtq 1/1 Running 0 2m39s tier=frontend frontend-r8kjt 1/1 Running 0 2m39s tier=frontend frontend-w7n98 1/1 Running 0 2m39s tier=frontend 这时我们尝试修改标签：将 tier 改为 frontend1 [root@apiserver ~]# kubectl label pod frontend-87wtq tier=frontend1 error: 'tier' already has a value (frontend), and --overwrite is false [root@apiserver ~]# kubectl label pod frontend-87wtq tier=frontend1 --overwrite=true pod/frontend-87wtq labeled [root@apiserver ~]# kubectl get pod --show-labels NAME READY STATUS RESTARTS AGE LABELS frontend-87wtq 1/1 Running 0 5m49s tier=frontend1 frontend-r8kjt 1/1 Running 0 5m49s tier=frontend frontend-w7n98 1/1 Running 0 5m49s tier=frontend frontend-wh4xx 1/1 Running 0 2s tier=frontend [root@apiserver ~]# kubectl get rs NAME DESIRED CURRENT READY AGE frontend 3 3 3 24m 这时我们会发现 rs 的数量没有变，pod 的数量多了一个，原因是 rs replicas: 3 是以标签 tier=frontend 为准，当标签修改后，他会自动新建一个和原来标签一样的 pod，当我们删掉 rs 之后，还会存留 tier=frontend1 的 pod deployment Deployment 为 Pod 和 Replica Set（下一代 Replication Controller）提供声明式更新。 你只需要在 Deployment 中描述你想要的目标状态是什么，Deployment controller 就会帮你将 Pod 和 Replica Set 的实际状态改变到你的目标状态。你可以定义一个全新的 Deployment，也可以创建一个新的替换旧的 Deployment。 一个典型的用例如下： 使用 Deployment 来创建 ReplicaSet。ReplicaSet 在后台创建 pod。检查启动状态，看它是成功还是失败。 然后，通过更新 Deployment 的 PodTemplateSpec 字段来声明 Pod 的新状态。这会创建一个新的 ReplicaSet，Deployment 会按照控制的速率将 pod 从旧的 ReplicaSet 移动到新的 ReplicaSet 中。 如果当前状态不稳定，回滚到之前的 Deployment revision。每次回滚都会更新 Deployment 的 revision。 扩容 Deployment 以满足更高的负载。 暂停 Deployment 来应用 PodTemplateSpec 的多个修复，然后恢复上线。 根据 Deployment 的状态判断上线是否 hang 住了。 清除旧的不必要的 ReplicaSet。 ","date":"2020-02-12","objectID":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/:3:0","tags":["资源控制器(RS,deployment)"],"title":"k8s资源控制器","uri":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/"},{"categories":["容器(🚢)"],"content":"演示 创建 deployment.yml 文档 apiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentspec:selector:matchLabels:app:nginxreplicas:2template:metadata:labels:app:nginxspec:containers:- name:nginximage:nginxports:- containerPort:80 创建 deployment [root@apiserver ~]# kubectl apply -f deployment.yaml --record #record 版本记录 deployment.extensions/nginx-deployment created 查看 deplyment [root@apiserver ~]# kubectl get deployments. NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 3/3 3 3 12s 查看 rs [root@apiserver ~]# kubectl get rs NAME DESIRED CURRENT READY AGE nginx-deployment-86bddccdd7 3 3 3 96s 查看 pod [root@apiserver ~]# kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-86bddccdd7-5s8ls 1/1 Running 0 19s nginx-deployment-86bddccdd7-9frh8 1/1 Running 0 19s nginx-deployment-86bddccdd7-wvcdx 1/1 Running 0 19s [root@apiserver ~]# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-deployment-86bddccdd7-5s8ls 1/1 Running 0 3m2s 192.168.102.179 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-9frh8 1/1 Running 0 3m2s 192.168.102.178 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-wvcdx 1/1 Running 0 3m2s 192.168.102.177 localhost.localdomain \u003cnone\u003e \u003cnone\u003e 查看程序是否正常运行(能访问页面即为正常) [root@apiserver ~]# curl 192.168.102.179 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eWelcome to nginx!\u003c/title\u003e \u003cstyle\u003e body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eWelcome to nginx!\u003c/h1\u003e \u003cp\u003e If you see this page, the nginx web server is successfully installed and working. Further configuration is required. \u003c/p\u003e \u003cp\u003e For online documentation and support please refer to \u003ca href=\"http://nginx.org/\"\u003enginx.org\u003c/a\u003e.\u003cbr /\u003e Commercial support is available at \u003ca href=\"http://nginx.com/\"\u003enginx.com\u003c/a\u003e. \u003c/p\u003e \u003cp\u003e\u003cem\u003eThank you for using nginx.\u003c/em\u003e\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e 扩容：扩容到原来的 10 倍 [root@apiserver ~]# kubectl scale deployment nginx-deployment --replicas=10 deployment.extensions/nginx-deployment scaled 查看 pod [root@apiserver ~]# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-deployment-86bddccdd7-5s8ls 1/1 Running 0 135m 192.168.102.179 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-9frh8 1/1 Running 0 135m 192.168.102.178 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-db44r 0/1 ContainerCreating 0 3s \u003cnone\u003e localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-gh2s4 0/1 ContainerCreating 0 3s \u003cnone\u003e localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-mmvc8 0/1 ContainerCreating 0 3s \u003cnone\u003e localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-sqzn7 0/1 ContainerCreating 0 3s \u003cnone\u003e localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-tb7k5 1/1 Running 0 3s 192.168.102.180 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-vtk8g 0/1 ContainerCreating 0 3s \u003cnone\u003e localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-wvcdx 1/1 Running 0 135m 192.168.102.177 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-86bddccdd7-z62js 0/1 ContainerCreating 0 3s \u003cnone\u003e localhost.localdomain \u003cnone\u003e \u003cnone\u003e 对镜像进行修改更新 [root@apiserver ~]# kubectl set image deployment/nginx-deployment nginx=linuxserver/nginx deployment.extensions/nginx-deployment image updated 查看 pod [root@apiserver ~]# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-deployment-d46468c78-6855p 1/1 Running 0 32s 192.168.102.135 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-d46468c78-lmnw7 1/1 Running 0 24s 192.168.102.138 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-d46468c78-lxhvq 1/1 Running 0 34s 192.168.102.132 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-d46468c78-mg7j7 1/1 Running 0 31s 192.168.102.136 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-deployment-d46468c78-mwcdt 1/1 Running 0 23s 192.168.102.143 localhost.localdomain \u003cnone\u003e \u003cnone\u003e nginx-d","date":"2020-02-12","objectID":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/:4:0","tags":["资源控制器(RS,deployment)"],"title":"k8s资源控制器","uri":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/"},{"categories":["容器(🚢)"],"content":"回滚的其它命令 查看回滚状态 [root@apiserver ~]# kubectl rollout status deployment nginx-deployment deployment \"nginx-deployment\" successfully rolled out 查看回滚历史 [root@apiserver ~]# kubectl rollout history deployment nginx-deployment deployment.extensions/nginx-deployment REVISION CHANGE-CAUSE 2 kubectl apply --filename=deployment.yaml --record=true 4 kubectl apply --filename=deployment.yaml --record=true 6 kubectl apply --filename=deployment.yaml --record=true 7 kubectl apply --filename=deployment.yaml --record=true 回滚到某一确定的历史版本 [root@apiserver ~]# kubectl rollout undo deployment nginx-deployment --to-revision=2 deployment.extensions/nginx-deployment rolled back ","date":"2020-02-12","objectID":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/:5:0","tags":["资源控制器(RS,deployment)"],"title":"k8s资源控制器","uri":"/k8s%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/"},{"categories":["容器(🚢)"],"content":"安装前准备 ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:0:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"kvm 准备 3 台虚拟机 kube-master kube-node1 kube-node2 ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:1:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"关闭防火墙 sudo ufw disable ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:2:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"关闭 swap 临时关闭 sudo swapoff -a 永久关闭 /etc/fstab 注释swap行 安装 docker ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:3:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"卸载旧 docker sudo apt-get remove docker docker-engine docker.io 彻底删除 docker-ce 和 docker-cli sudo apt-get autoremove docker-ce ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:4:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"安装依赖 sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:5:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"添加 docker 的 gpg key 为了使用 https 访问，使用阿里云加速 curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:6:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"设置 docker 镜像源 sudo add-apt-repository \\ \"deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu \\ $(lsb_release -cs)\\ stable\" 更新源 sudo apt update \u0026\u0026 sudo apt-get update ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:7:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"安装 docker 18.06 查看 docker-ce 版本 apt-cache madison docker-ce 安装指定版本 sudo apt-get install -y docker-ce=18.06.3~ce~3-0~ubuntu ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:8:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"默认启动 sudo systemctl enable docker \u0026\u0026 sudo systemctl start docker ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:9:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"修改 docker 启动参数，进行加速 sudo tee /etc/docker/daemon.json \u003c\u003c-'EOF' { \"registry-mirrors\": [ \"https://1nj0zren.mirror.aliyuncs.com\", \"https://docker.mirrors.ustc.edu.cn\", \"http://f1361db2.m.daocloud.io\", \"https://registry.docker-cn.com\" ] } EOF sudo systemctl daemon-reload sudo systemctl restart docker 安装 kubernets ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:10:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"更新 apt 源 sudo apt-get update \u0026\u0026 sudo apt-get install -y apt-transport-https curl sudo curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - sudo tee /etc/apt/sources.list.d/kubernetes.list \u003c\u003c-'EOF' deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main EOF sudo apt-get update ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:11:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"安装 kubectl kubeadm kubelet 在 master 和 node 上都安装 sudo apt-get install -y kubelet=1.17.3-00 kubeadm=1.17.3-00 kubectl=1.17.3-00 sudo apt-mark hold kubelet=1.17.3-00 kubeadm=1.17.3-00 kubectl=1.17.3-00 ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:12:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"启动 kubelet sudo systemctl enable kubelet \u0026\u0026 sudo systemctl start kubelet ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:13:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"初始化集群(master) 在国内有些众所周知的原因我们无法 kubeadm 初始化是无法连接到谷歌仓库的 在 master 上执行下面脚本后再初始化 root@kube-master:~# cat k8s.sh docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.17.3 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.17.3 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.17.3 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.17.3 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.4.3-0 docker pull coredns/coredns:1.6.5 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.17.3 k8s.gcr.io/kube-apiserver:v1.17.3 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.17.3 k8s.gcr.io/kube-controller-manager:v1.17.3 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.17.3 k8s.gcr.io/kube-scheduler:v1.17.3 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.17.3 k8s.gcr.io/kube-proxy:v1.17.3 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.4.3-0 k8s.gcr.io/etcd:3.4.3-0 docker tag coredns/coredns:1.6.5 k8s.gcr.io/coredns:1.6.5 docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.17.3 docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.17.3 docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.17.3 docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.17.3 docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.4.3-0 docker rmi coredns/coredns:1.6.5 开始初始化 root@kube-master:~# kubeadm init --kubernetes-version v1.17.3 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16 保留初始化最后的 token(在添加 node 时使用) kubeadm join 192.168.1.6.554:6443 --token ekw68p.rzmiyxxviu1pqu80 --discovery-token-ca-cert-hash sha256:45234a6478890244c7ddedb49b88c4aac5a745c277c7221efbcf7d622788f798 ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:14:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"安装网络插件(flannel) 下载配置文件 wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 更改配置文件 root@kube-master:/var/tmp/0206# diff -u kube-flannel.yml ~/kube-flannel.yml --- kube-flannel.yml 2020-02-06 14:05:30.240084193 +0000 +++ /root/kube-flannel.yml 2020-02-06 08:05:43.654959409 +0000 @@ -169,7 +169,7 @@ serviceAccountName: flannel initContainers: - name: install-cni - image: quay.io/coreos/flannel:v0.11.0-amd64 + image: lizhenliang/flannel:v0.11.0-amd64 command: - cp args: @@ -183,7 +183,7 @@ mountPath: /etc/kube-flannel/ containers: - name: kube-flannel - image: quay.io/coreos/flannel:v0.11.0-amd64 + image: lizhenliang/flannel:v0.11.0-amd64 command: - /opt/bin/flanneld args: 安装网络插件 kubectl apply -f kube-flannel.yml 检查 master 状态(ready 为成功) root@kube-master:~# kubectl get nodes NAME STATUS ROLES AGE VERSION kube-master Ready master 6h12m v1.17.3 ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:15:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"加入 node node 执行下面脚本 root@kube-node-1:~# cat k8s-node.sh docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.17.3 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.17.3 k8s.gcr.io/kube-proxy:v1.17.3 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1 docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.17.3 docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:16:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"node 加入集群 kubeadm join 192.168.1.6.554:6443 --token ekw68p.rzmiyxxviu1pqu80 --discovery-token-ca-cert-hash sha256:45234a6478890244c7ddedb49b88c4aac5a745c277c7221efbcf7d622788f798 ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:17:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["容器(🚢)"],"content":"master 上检查集群状态 root@kube-master:~# kubectl get nodes NAME STATUS ROLES AGE VERSION kube-master Ready master 6h12m v1.17.3 kube-node-1 Ready \u003cnone\u003e 5h48m v1.17.3 kube-node-2 Ready \u003cnone\u003e 5h44m v1.17.3 root@kube-master:~# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-576cbf47c7-2qq7p 1/1 Running 1 6h18m coredns-576cbf47c7-7xl9z 1/1 Running 1 6h18m etcd-kube-master 1/1 Running 1 6h9m kube-apiserver-kube-master 1/1 Running 1 6h9m kube-controller-manager-kube-master 1/1 Running 1 6h9m kube-flannel-ds-amd64-fzhft 1/1 Running 0 5h55m kube-flannel-ds-amd64-p8cpp 1/1 Running 1 6h10m kube-flannel-ds-amd64-v4688 1/1 Running 1 5h51m kube-proxy-5dnzv 1/1 Running 1 6h18m kube-proxy-hzksv 1/1 Running 1 5h51m kube-proxy-rtwtc 1/1 Running 0 5h55m kube-scheduler-kube-master 1/1 Running 1 6h9m ","date":"2020-02-06","objectID":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/:18:0","tags":["k8s搭建"],"title":"ubuntu1804国内使用kubeadm部署k8s","uri":"/ubuntu1804%E5%9B%BD%E5%86%85%E4%BD%BF%E7%94%A8kubeadm%E9%83%A8%E7%BD%B2k8s/"},{"categories":["NetBackup"],"content":"NetBackup 测试 ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:0:0","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"客户端安装(供应商暂时提供的方法) 供应商提供安装包(NetBackup_8.2_CLIENTS_debian.tar.gz) Linux 下需要手动配置 hosts 文件 client 端指定 master 端 ip 10.1.1.75 C01R7NBU01 master 端指定 client 端 ip 10.1.7.71 nj-zabbix-2-te 在 client 端解压压缩包开始安装(比较繁琐) ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:1:0","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"备份 ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:2:0","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"linux 文件备份 将刚自动发现的客户端加到对应的策略组 配置备份策略类型(attributes) 配置自动备份策略 配置文件备份路径 ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:2:1","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"mysql 备份(无法进行依赖脚本) master 如何调用脚本 全备份 增量备份 ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:2:2","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"postgresql 备份(无法进行依赖脚本) master 如何调用脚本 全备份 增量备份 ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:2:3","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"redis 文件备份(官网为提供可使用文件备份来备份) 使用 linux 文件备份 ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:2:4","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"api 基础测试 ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:3:0","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"获取认证 token url=\"https://c01r7nbu01.genscript.com:1556/netbackup/login\" tokenget(){ curl -k -X POST -H 'Content-type: application/vnd.netbackup+json;version=1.0' -d ' { \"userName\":\"root\", \"password\":\"*********\" }' $url } tokenget ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:3:1","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"新增备份服务器 url=\"https://c01r7nbu01.genscript.com:1556/netbackup/config/hosts\" token=\"*************\" curl -k -X POST $url \\ -H 'Content-type: application/vnd.netbackup+json;version=3.0' \\ -H 'Authorization: '$token'' \\ -d '{\"hostName\": \"nj-lab-1-it\"}' ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:3:2","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"新增备份任务 url=\"https://c01r7nbu01.genscript.com:1556/netbackup/config/policies/Linux_Bakcup/clients/nj-zabbix-1-te\" token=\"*************\" curl -k -X PUT \\ -H 'Content-type: application/vnd.netbackup+json;version=3.0' \\ -H 'authorization: '$token'' -d ' { \"data\": { \"type\": \"client\", \"id\": \"nj-zabbix-1-te\", \"attributes\": { \"OS\": \"Debian2.6.32\", \"hardware\": \"Linux\" } } }' $url ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:3:3","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["NetBackup"],"content":"未完待续(api 足够丰富)。。。。。。 ","date":"2020-01-02","objectID":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/:3:4","tags":["nbu备份"],"title":"linux-nbu测试报告","uri":"/linux-nbu%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"},{"categories":["linux(🐧)"],"content":"背景 40GB(sys)256GB*(data)，合并成为一个 lvm 逻辑分区 ubuntu-root 目标 最小代价实现 lvm 扩容 64GB 方法 新建一块 64GB 虚拟硬盘，合并到 ubuntu-root 逻辑分区 优点：风险最小 缺点：多一块 64GB 虚拟磁盘 新建一块 320GB 虚拟磁盘，转移原 256GB 数据后，删除 256GB 虚拟磁盘 优点：只保留一块 320GB 虚拟磁盘 缺点：代价高 增加 256GB 虚拟磁盘容量，直接动态扩容到 320GB 优点：技能 GET 缺点：未知风险高 操作 在 vClient 修改虚拟磁盘（假定未 sdb）的容量，从 256GB 调整到 320GB 重启服务器（不建议）、或强制重新扫描磁盘（具体那个实际有效暂不清楚） echo 1 \u003e /sys/class/scsi_disk/2:0:0:0/device/rescan echo ‘- - -’ \u003e /sys/class/scsi_host/host2/scan echo 1 \u003e /sys/block/sdb/device/rescan (确认有效) partprobe -s 分两种情况，A）sdb 未分区、直接整盘加入 lvm 的情况 确认 sdb 磁盘容量已增加 (fdisk) 执行 pvresize /dev/sdb 对 LVM 的物理分区扩容 对 LVM 的逻辑分区扩容(略) 第二种情况，B）sdb 已分区、某个（些）分区加入 lvm 的情况（假如 sdb5） 确认 sdb 磁盘容量已增加 (fdisk) 通过 parted /dev/sdb 对 sdb5 分区扩容 (注意，如果分区是在扩展分区中，需要先把扩展分区扩容) root@nj-otter-en-qa:/opt/logstash# parted /dev/sda GNU Parted 2.3 Using /dev/sda Welcome to GNU Parted! Type help'' to view a list of commands. parted)( p Model: VMware Virtual disk (scsi) Disk /dev/sda: 68.7GB Sector size (logical/physical): 512B/512B Partition Table: msdos Number Start End Size Type File system Flags 1 1049kB 256MB 255MB primary ext2 boot 2 257MB 42.9GB 42.7GB extended 5 257MB 42.9GB 42.7GB logical lvm (parted) resizepart 2 End? [68.0GB]? 68.7GB (parted) p Model: VMware Virtual disk (scsi) Disk /dev/sda: 68.7GB Sector size (logical/physical): 512B/512B Partition Table: msdos Number Start End Size Type File system Flags 1 1049kB 256MB 255MB primary ext2 boot 2 257MB 68.7GB 68.4GB extended 5 257MB 42.9GB 42.7GB logical lvm (parted) resizepart 5 End? [42.9GB]? 68.7GB Error: Error informing the kernel about modifications to partition /dev/sda5 -- Invalid argument. This means Linux won't know about any changes you made to /dev/sda5 until you reboot -- so you shouldn't mount it or use it in any way before rebooting. Ignore/Cancel? cancel Error: Partition(s) 5 on /dev/sda have been written, but we have been unable to inform the kernel of the change, probably because it/they are in use. As a result, the old partition(s) will remain in use. You should reboot now before making further changes. Ignore/Cancel? Cancel (parted) p Model: VMware Virtual disk (scsi) Disk /dev/sda: 68.7GB Sector size (logical/physical): 512B/512B Partition Table: msdos Number Start End Size Type File system Flags 1 1049kB 256MB 255MB primary ext2 boot 2 257MB 68.7GB 68.4GB extended 5 257MB 68.7GB 68.4GB logical lvm 执行 pvresize /dev/sdb5 对 LVM 的物理分区扩容 对 LVM 的逻辑分区扩容(略) ","date":"2019-11-06","objectID":"/vmware-linux%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/:0:0","tags":["lvm"],"title":"Vmware-linux虚拟机的磁盘扩容","uri":"/vmware-linux%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9/"},{"categories":["键盘(⌨)"],"content":"场景 老是心水优联超强的续航，寻思整一个优联主控的键盘，现是面上有 k230、k270、k375s 主控， 在这里我选择了 k230 主控，毕竟我对蓝牙没有需求，在这里就不演示如何组装一把优联机械键 键盘了，演示下 Linux 下如何对 u2u 刷固件，毕竟优联的 fn 键很弱鸡。 u2u 介绍 u2u 是github上的一个开源项目，是对普通键盘键位更改，实现多层和宏。 u2u 如何刷固件 在这里我们需要使用以下 2 个网站kle 和tkg kle 是用来生成键盘配列，tkg 使用来时生成固件和刷写固件的，将你的键盘配列在 kle 上画好，说下各个层的作用，原始层必须和你的优联键盘键位一致(我改的 84 键盘所以配列就是网站上的凯酷 84 改的)，第 0 层是你接上电脑时显示的那一层，第 1 层是你定义的 fn1 的第一层，第 2 层依次类推。 ","date":"2019-09-27","objectID":"/%E4%BC%98%E8%81%94k230%E4%BD%BF%E7%94%A8usb2usb/:0:0","tags":["Unifying"],"title":"优联k230使用usb2usb","uri":"/%E4%BC%98%E8%81%94k230%E4%BD%BF%E7%94%A8usb2usb/"},{"categories":["键盘(⌨)"],"content":"使用 kle 修改配列 优联 84 原始层 k230 优联 84 第 0 层 k2300 优联 84 第 1 层 k2301 ","date":"2019-09-27","objectID":"/%E4%BC%98%E8%81%94k230%E4%BD%BF%E7%94%A8usb2usb/:1:0","tags":["Unifying"],"title":"优联k230使用usb2usb","uri":"/%E4%BC%98%E8%81%94k230%E4%BD%BF%E7%94%A8usb2usb/"},{"categories":["键盘(⌨)"],"content":"使用 tkg 刷固件 将原始层填入设定中 将第 0 层和第一层填入层中 fn 设定 优联 84 的原始 fn 键是多媒体按键，在这里我设置 fn0 给原 fn 并不做任何操作，设置 space 键为 fn1 键并保留空格键功能。 chrome 安装 TKG Chrome App 插件 听说 windows 下要安全驱动？？？？linux 不存在的(有 avr 编程环境就行) 按下刷机键就开始烧写吧！ 当然你也可以使用 avrdude 刷 ","date":"2019-09-27","objectID":"/%E4%BC%98%E8%81%94k230%E4%BD%BF%E7%94%A8usb2usb/:2:0","tags":["Unifying"],"title":"优联k230使用usb2usb","uri":"/%E4%BC%98%E8%81%94k230%E4%BD%BF%E7%94%A8usb2usb/"},{"categories":["GO"],"content":"前言 闲着没事，看 python 不爽，决定重构 mutt-lday.py 实现 viper 读取配置文件 ldap 解析配置文件 ","date":"2019-09-10","objectID":"/ldap%E6%90%9C%E7%B4%A2/:0:0","tags":["neomutt"],"title":"ldap搜索","uri":"/ldap%E6%90%9C%E7%B4%A2/"},{"categories":["GO"],"content":"代码实现 // Package main provides ... package main import ( \"fmt\" \"os\" log \"github.com/sirupsen/logrus\" \"github.com/spf13/viper\" \"gopkg.in/ldap.v2\" ) type connection struct { Server string `json:\"server\"` Port int `json:\"port\"` Basedn string `json:\"basedn\"` } type auth struct { User string `json:\"user\"` Password string `json:\"password\"` } type result struct { OptionalColumn string `json:\"optionalcolumn\"` } type searchConfig struct { Connection connection `json:\"connection\"` Auth auth `json:\"auth\"` Result result `json:\"result\"` } type searchResult struct { Mail string Name string } var matchAttributes = []string{\"uid\", \"cn\"} var displayAttributes = []string{\"mail\", \"cn\"} func (conf *searchConfig) init() { viper.SetConfigName(\"mutt-ldap\") viper.SetConfigType(\"json\") viper.AddConfigPath(\"./\") viper.AddConfigPath(\"~/.config/\") if err := viper.ReadInConfig(); err != nil { log.Fatalf(\"Error reading config file, %s\", err) } if err := viper.Unmarshal(conf); err != nil { log.Fatalf(\"unable to decode into struct, %v\", err) } log.Tracef(\"searchConfig.connection %v\", conf.Connection) log.Tracef(\"searchConfig.auth %v\", conf.Auth) log.Tracef(\"searchConfig.result %v\", conf.Result) } func searchLdap(conf *searchConfig, term string) ([]searchResult, error) { filter := \"(\u0026(|\" for _, attr := range matchAttributes { filter = fmt.Sprintf(\"%s(%s=*%s*)\", filter, attr, term) } filter = fmt.Sprintf(\"%s)(mail=*))\", filter) conn, err := ldap.Dial(\"tcp\", fmt.Sprintf(\"%s:%d\", conf.Connection.Server, conf.Connection.Port)) if err != nil { log.Fatalf(\"Conn to server fail, %s\", err) } defer conn.Close() if err := conn.Bind(conf.Auth.User, conf.Auth.Password); err != nil { log.Fatalf(\"Bind to server fail, %s\", err) } searchresult := ldap.NewSearchRequest(conf.Connection.Basedn, ldap.ScopeWholeSubtree, ldap.NeverDerefAliases, 0, 0, false, filter, displayAttributes, nil) sr, err := conn.Search(searchresult) if err != nil { log.Fatalf(\"search error, %s\", err) } res := make([]searchResult, len(sr.Entries)) for idx, entry := range sr.Entries { res[idx].Mail = entry.GetAttributeValue(\"mail\") res[idx].Name = entry.GetAttributeValue(\"cn\") } return res, nil } func printResult(ldapRes []searchResult) { for _, entry := range ldapRes { fmt.Printf(\"%s\\t%s\\n\", entry.Mail, entry.Name) } } func main() { if len(os.Args) \u003c 2 { fmt.Println(\"usage:error\") os.Exit(0) } var c searchConfig c.init() ldapRes, err := searchLdap(\u0026c, os.Args[1]) if err != nil { log.Fatal(err) os.Exit(1) } printResult(ldapRes) } ","date":"2019-09-10","objectID":"/ldap%E6%90%9C%E7%B4%A2/:1:0","tags":["neomutt"],"title":"ldap搜索","uri":"/ldap%E6%90%9C%E7%B4%A2/"},{"categories":["GO"],"content":"json 文件配置  ~/go/src/day_test 15:08:27  cat mutt-ldap.json { \"connection\": { \"server\": \"*********\", \"port\": \"389\", \"basedn\": \"DC=********,DC=com\" }, \"auth\": { \"user\": \"*******\", \"password\": \"*********\" }, \"result\": { \"optionalcolumn\": \"sAMAccountName\" } } ","date":"2019-09-10","objectID":"/ldap%E6%90%9C%E7%B4%A2/:2:0","tags":["neomutt"],"title":"ldap搜索","uri":"/ldap%E6%90%9C%E7%B4%A2/"},{"categories":["linux(🐧)"],"content":"场景 开发人员给定数据路径，使用 exel 显示，将 exel 转化为 csv。 方法 批量导出脚本 #!/bin/bash while read line; do ROOM=$(echo $line | awk -F',' '{print $3\"/\"$1\"/\"$1\"_\"$4}') TARGET=$(echo $line | awk -F',' '{print $9}') LINK_NAME=$(echo $line | awk -F',' '{print $8}') if [[ -e $TARGET ]]; then /bin/mkdir -p \"$ROOM\" /bin/ln -bv -sf \"$TARGET\" \"$ROOM/$LINK_NAME\" fi done \u003c\u003c\u003c \"$(tail -n +2 foo02.csv)\" 批量打包 ls -1 | xargs -I{} zip -r \"{}.zip\" {} find 2016/ -name \"*.zip\" -exec mv {} /var/tmp/0415/gsk/2016/ \\; ","date":"2019-08-27","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%89%B9%E9%87%8F%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE/:0:0","tags":["导出数据"],"title":"记一次批量导出数据","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%89%B9%E9%87%8F%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE/"},{"categories":["GO"],"content":"切片 ","date":"2019-08-20","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/:0:0","tags":["切片"],"title":"从零开始学Golang-切片","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/"},{"categories":["GO"],"content":"切片的定义 切片的声明 var name []T name:变量名 T:变量类型 ","date":"2019-08-20","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/:1:0","tags":["切片"],"title":"从零开始学Golang-切片","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/"},{"categories":["GO"],"content":"切片的长度和容量 切片拥有自己的长度和容量，可以使用内置的 len()函数求长度，使用内置的 cap()函数求切片的容量。 ","date":"2019-08-20","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/:2:0","tags":["切片"],"title":"从零开始学Golang-切片","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/"},{"categories":["GO"],"content":"基于数组定义切片 由于切片的底层就是一个数组，我们可以基于数组定义切片。 func main() { //基于数组定义切片 a := [5]int{55,56,57,58,59} b := a[1:4] fmt.Println(b) fmt.Println(\"type of b:%T\\n\",b) } /* c := a[1:] [56,57,58,59] d := a[:4] [55,56,57] e := a[:] [全都要] */ ","date":"2019-08-20","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/:3:0","tags":["切片"],"title":"从零开始学Golang-切片","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/"},{"categories":["GO"],"content":"切片再切片 func main() { //切片再切片 a := [...]string{\"北京\", \"上海\", \"广州\", \"深圳\", \"成都\", \"重庆\"} fmt.Printf(\"a:%v type:%T len:%d cap:%d\\n\", a, a, len(a), cap(a)) b := a[1:3] fmt.Printf(\"b:%v type:%T len:%d cap:%d\\n\", b, b, len(b), cap(b)) c := b[1:5] fmt.Printf(\"c:%v type:%T len:%d cap:%d\\n\", c, c, len(c), cap(c)) } ","date":"2019-08-20","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/:4:0","tags":["切片"],"title":"从零开始学Golang-切片","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/"},{"categories":["GO"],"content":"使用make()函数构造切片 语法： make([]T,size,cap) T:切片的元素类型 size:切片长度（元素数量） cap:切片的容量 ","date":"2019-08-20","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/:5:0","tags":["切片"],"title":"从零开始学Golang-切片","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/"},{"categories":["GO"],"content":"切片的本质 切片的本质就是对底层数组的封装，它包含了三个信息：底层数组的指针、切片的长度（len）和切片的容量（cap）。 ","date":"2019-08-20","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/:6:0","tags":["切片"],"title":"从零开始学Golang-切片","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/"},{"categories":["GO"],"content":"使用 append() 向切片内添加元素 func main() { //append()添加元素和切片扩容 var numSlice []int for i := 0; i \u003c 10; i++ { numSlice = append(numSlice, i) fmt.Printf(\"%v len:%d cap:%d ptr:%p\\n\", numSlice, len(numSlice), cap(numSlice), numSlice) } } ","date":"2019-08-20","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/:7:0","tags":["切片"],"title":"从零开始学Golang-切片","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/"},{"categories":["GO"],"content":"切片的赋值和拷贝 切片的赋值实际都是指向了同一个内存地址，修改一个切片的值另一个也会跟着更改。 切片的拷贝使用copy()函数 语法： copy(destSlice, srcSlice []T) srcSlice: 数据来源切片 destSlice: 目标切片 ","date":"2019-08-20","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/:8:0","tags":["切片"],"title":"从零开始学Golang-切片","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/"},{"categories":["GO"],"content":"切片的遍历 一般情况下都使用for range遍历 func main() { s := []int{1, 3, 5} for i := 0; i \u003c len(s); i++ { fmt.Println(i, s[i]) } for index, value := range s { fmt.Println(index, value) } } 注意 切片是引用类型，切片赋值实际都是指向同一个内存地址 ","date":"2019-08-20","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/:9:0","tags":["切片"],"title":"从零开始学Golang-切片","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%88%87%E7%89%87/"},{"categories":["dotfile配置"],"content":"场景 vim 用久了总想用 vim 来编辑邮件，可是公司的邮箱是 exchange 很头疼，好在最后找到了 davmail 这么个玩意。 davmail 配置邮件交换 ","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:0:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["dotfile配置"],"content":"下载 个人不太喜欢图形界面，所以直接用 davmail server 版 下载地址 如果不能下载请自行爬墙 ","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:1:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["dotfile配置"],"content":"配置 /etc/davmail.properties # DavMail settings, see http://davmail.sourceforge.net/ for documentation ############################################################# # Basic settings # Server or workstation mode davmail.server=true # connection mode auto, EWS or WebDav davmail.enableEws=true # base Exchange OWA or EWS url davmail.url=https://******公司邮件服务器地址******/EWS/Exchange.asmx # Listener ports davmail.caldavPort=1080 davmail.imapPort=1143 davmail.ldapPort=1389 davmail.popPort=1110 davmail.smtpPort=1025 ############################################################# # Network settings # Network proxy settings davmail.enableProxy=false davmail.useSystemProxies=false davmail.proxyHost= davmail.proxyPort= davmail.proxyUser= davmail.proxyPassword= # proxy exclude list davmail.noProxyFor= # allow remote connection to DavMail davmail.allowRemote=false # bind server sockets to a specific address davmail.bindAddress= # client connections SO timeout in seconds davmail.clientSoTimeout= # DavMail listeners SSL configuration davmail.ssl.keystoreType= davmail.ssl.keystoreFile= davmail.ssl.keystorePass= davmail.ssl.keyPass= # Accept specified certificate even if invalid according to trust store davmail.server.certificate.hash= # disable SSL for specified listeners davmail.ssl.nosecurecaldav=false davmail.ssl.nosecureimap=false davmail.ssl.nosecureldap=false davmail.ssl.nosecurepop=false davmail.ssl.nosecuresmtp=false # disable update check davmail.disableUpdateCheck=false # Send keepalive character during large folder and messages download davmail.enableKeepAlive=false # Message count limit on folder retrieval davmail.folderSizeLimit=0 # Default windows domain for NTLM and basic authentication davmail.defaultDomain= ############################################################# # Caldav settings # override default alarm sound davmail.caldavAlarmSound= # retrieve calendar events not older than 90 days davmail.caldavPastDelay=90 # WebDav only: force event update to trigger ActiveSync clients update davmail.forceActiveSyncUpdate=false ############################################################# # IMAP settings # Delete messages immediately on IMAP STORE \\Deleted flag davmail.imapAutoExpunge=true # Enable IDLE support, set polling delay in minutes davmail.imapIdleDelay= # Always reply to IMAP RFC822.SIZE requests with Exchange approximate message size for performance reasons davmail.imapAlwaysApproxMsgSize= ############################################################# # POP settings # Delete messages on server after 30 days davmail.keepDelay=30 # Delete messages in server sent folder after 90 days davmail.sentKeepDelay=90 # Mark retrieved messages read on server davmail.popMarkReadOnRetr=false ############################################################# # SMTP settings # let Exchange save a copy of sent messages in Sent folder davmail.smtpSaveInSent=true ############################################################# # Loggings settings # log file path, leave empty for default path davmail.logFilePath=/var/log/davmail.log # maximum log file size, use Log4J syntax, set to 0 to use an external rotation mechanism, e.g. logrotate davmail.logFileSize=1MB # log levels log4j.logger.davmail=WARN log4j.logger.httpclient.wire=WARN log4j.logger.org.apache.commons.httpclient=WARN log4j.rootLogger=WARN ############################################################# # Workstation only settings # smartcard access settings davmail.ssl.pkcs11Config= davmail.ssl.pkcs11Library= # SSL settings for mutual authentication davmail.ssl.clientKeystoreType= davmail.ssl.clientKeystoreFile= davmail.ssl.clientKeystorePass= # disable all balloon notifications davmail.disableGuiNotifications=false # disable startup balloon notifications davmail.showStartupBanner=true # enable transparent client Kerberos authentication davmail.enableKerberos=false 使用 supervisor 将 davmail 守护起来(使用 apt、yum、pacman 直接安装) 编辑/etc/supervisor.d/davmail.ini [program:DavMail] command=/opt/davmail/davmail.sh /","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:2:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["dotfile配置"],"content":"安装 不在赘述（apt、yum、pacman）直接安装 ","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:3:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["dotfile配置"],"content":"配置 ~/.fetchmailrc （没有就自己创建一个） defaults mda \"/usr/bin/procmail -d %T\" set idfile /home/luwenzheng/Maildir/.fetchids\"\" set no bouncemail set postmaster \"luwenzheng\" poll 127.0.0.1 with protocol imap port 1143 uidl username \"luwenzheng@genscript.com\" there with password \"********\" is 'luwenzheng' here options keep promail 过滤邮件 ","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:4:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["dotfile配置"],"content":"安装 不在赘述（apt、yum、pacman）直接安装 ","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:5:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["dotfile配置"],"content":"配置 ~/.procmailrc (没有就自己创建一个) MAILDIR=/home/luwenzheng/Maildir #邮件存储地址 DEFAULT=$MAILDIR/inbox #默认：收件箱 VERBOSE=off LOGFILE=/var/log/Mail/procmail.log # 某个垃圾邮件规则 :0 * ^From: webmaster@st\\.zju\\.edu\\.cn /dev/null #垃圾文件的存储位置 # 其它所有都存到收件箱中 :0: inbox/ procmail 中的路径需要自己创建 接下来你就可以使用 fetchmail -a 收取全部邮件了 mstmp 发送邮件 ","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:6:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["dotfile配置"],"content":"安装 不在赘述（apt、yum、pacman）直接安装 ","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:7:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["dotfile配置"],"content":"配置 ~/.mstmprc （没有就自己创建一个） defaults logfile /home/luwenzheng/Maildir/msmtp.log account genscript host 127.0.0.1 from luwenzheng@genscript.com user luwenzheng password ******** port 1025 auth plain account default:genscript neomutt （邮件客户端） ","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:8:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["dotfile配置"],"content":"安装 不在赘述（apt、yum、pacman）直接安装 ","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:9:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["dotfile配置"],"content":"配置 ~/.config/neomutt 路径下有大量配置文件，各类个性话定制详细配置请查看我的 dotfile ","date":"2019-08-19","objectID":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/:10:0","tags":["邮件客户端"],"title":"neomutt+procmail+fetchmail+msmtp配置exchange邮箱","uri":"/neomutt-procmail-fetchmail-msmtp%E9%85%8D%E7%BD%AEexchange%E9%82%AE%E7%AE%B1/"},{"categories":["linux(🐧)"],"content":"场景 每个月内核都会自动更新，导致/boot 满需要手动清理，于是忍不了禁用内核更新 方法 修改/etc/apt/apt.conf.d/50unattended-upgrades root@nj-app-bfin-edoc-qa:/etc/apt/apt.conf.d# diff -u /var/tmp/0701/50unattended-upgrades 50unattended-upgrades --- /var/tmp/0701/50unattended-upgrades 2017-07-16 21:31:51.358164036 +0800 +++ 50unattended-upgrades 2019-07-01 10:25:09.830049417 +0800 @@ -14,6 +14,7 @@ // List of packages to not update (regexp are supported) Unattended-Upgrade::Package-Blacklist { + \"linux-.*?-generic\"; // \"vim\"; // \"libc6\"; // \"libc6-dev\"; ","date":"2019-08-19","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1ubuntu%E7%A6%81%E7%94%A8%E5%86%85%E6%A0%B8%E6%9B%B4%E6%96%B0/:0:0","tags":["禁用内核更新"],"title":"记一次ubuntu禁用内核更新","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1ubuntu%E7%A6%81%E7%94%A8%E5%86%85%E6%A0%B8%E6%9B%B4%E6%96%B0/"},{"categories":["GO"],"content":"基本数据类型 ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:0:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"整型 类型 描述 uint8 无符号 8 位整型(0 到 255) uint16 无符号 16 位整型(0 到 255) uint32 无符号 32 位整型(0 到 255) uint64 无符号 64 位整型(0 到 255) int8 有符号 8 位整型(-128 到 127) int16 有符号 16 位整型(-128 到 127) int32 有符号 32 位整型(-128 到 127) int64 有符号 32 位整型(-128 到 127) ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:1:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"特殊整型 类型 描述 uint 32 位操作系统上就是 uint32，64 位操作系统就是 uint64 int 32 位操作系统上就是 int32，64 位操作系统就是 int64 uintptr 无符号整型，用于存放一个指针 ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:2:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"浮点型 类型 描述 float32 最大范围约为 3.4e38，可以使用常量定义 float64 最大范围约为 1.8e308，可以使用常量定义 ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:3:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"布尔类型 类型 描述 true 真 false 假 ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:4:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"字符串转义字符 转义符 含义 \\r 回车符（返回行首） \\n 换行符（直接跳到下一行的同列位置） \\t 制表符 ' 单引号 \" 双引号 \\ 反斜杠 ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:5:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"多行字符串 Go 语言中要定义多行字符串时，必须使用`` sl :=`第一行 第二行 第三行 ` ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:6:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"字符串的常用操作 方法 介绍 len(str) 求长度 + 拼接字符串 strings.Split 分割 strings.contains 判断是否包含 strings.HasPrefix,strings.HasSuffix 前后缀判断 strings.Index(),strings.LastIndex() 字符串出现的位置 strings.Join(a[]string,sep string) join 操作 ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:7:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"byte 和 rune 类型 Go 语言的字符有以下俩种: uint8 类型，或者叫 byte类型，代表了 ASCII 码的一个字符。 rune类型，代表一个 UTF-8 字符。 当需要处理中文、日文或者其他复合字符时，则需要用到rune类型类型实际是一个 int32。 ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:8:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"修改字符串 要修改字符串，需要先将其转换成[]rune或 byte[]，完成后再转化成string。无论那种转换，都会重新分配内存，并复制字节数组。 func changeString() { s1 := \"big\" //强制类型转换 byteS1 := []byte(s1) byteS1[0] = 'p' fmt.Println(string(byteS1)) s2 := \"白萝卜\" //强制类型转换 runeS2 := []rune(s2) runeS2[0] = \"胡\" fmt.Println(string(runeS2)) } ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:9:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"类型转换 Go 语言只有强制类型转换，没有隐式类型转换。（该语法只能在两个类型之间支持相互转换的时候使用），语法如下 T(表达式) 其中，T 表示要转换的类型。表达式包括变量、函数返回值等。 func sqrtDemo() { a,b := 3,4 var c int c = int(math.Sqrt(float64(a*a + b*b))) fmt.Println(c) } ","date":"2019-08-19","objectID":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/:10:0","tags":["Golang基本数据类型"],"title":"Go基本数据类型","uri":"/go%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"categories":["GO"],"content":"前言 不知道从什么时候开始决定要深入学习一门开发语言了，从 17 年开始工作的时候漫无目的的学习 python 到现在，python 平时也会写但是大概还停留在抄代码的阶段吧！18 年 9 月入职了新公司，受小伙伴影响对 Golang 开始感兴趣了，从 6 月到现在陆陆续续学习总是没有头绪，可能时间太过闲散，每次学习一次大概要过很久很久才会继续学习，知识点忘了，现在从头开始吧！都记录在博客上。 变量 ","date":"2019-08-18","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/:0:0","tags":["Golang(变量)"],"title":"从零开始学习Golang(变量)","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/"},{"categories":["GO"],"content":"变量声明 Go 语言中的变量必声明后才能使用，同一作用域内不支持重复声明。 ","date":"2019-08-18","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/:1:0","tags":["Golang(变量)"],"title":"从零开始学习Golang(变量)","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/"},{"categories":["GO"],"content":"标准声明 Go 语言到变量声明格式为： var 变量名 变量类型 变量声明以关键字var开头，变量类型放在变量后面，行尾不需要分号(这一点后 C 不同) var name string var age int var ok bool ","date":"2019-08-18","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/:2:0","tags":["Golang(变量)"],"title":"从零开始学习Golang(变量)","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/"},{"categories":["GO"],"content":"批量声明 Go 语言是支持批量声明的。 var { a string b int c bool d float64 } ","date":"2019-08-18","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/:3:0","tags":["Golang(变量)"],"title":"从零开始学习Golang(变量)","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/"},{"categories":["GO"],"content":"变量的初始化 Go 语言在声明变量到时候，会自动对变量对应到内存区域进行初始化操作，每个变量都会被初始化为其类型的默认值，例如：整型和浮点型的默认值为0。 字符串变量的默认值为空字符串。布尔型变量的默认值为false。切片、函数、指针变量到默认值为nil。 我们也可以在声明变量时指定初始值。 var 变量名 类型=表达式 var name string=\"gaojila\" var age int=25 我们也可以一次性初始化多个变量。 var name,age=\"gaojila\",25 ","date":"2019-08-18","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/:4:0","tags":["Golang(变量)"],"title":"从零开始学习Golang(变量)","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/"},{"categories":["GO"],"content":"类型推倒 有时候我们会将变量的类型省略，这个时候编译器会根据等号右边的值来推导变量的类型完成初始化。 var name=\"gaojila\" var age=25 ","date":"2019-08-18","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/:5:0","tags":["Golang(变量)"],"title":"从零开始学习Golang(变量)","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/"},{"categories":["GO"],"content":"短变量声明 在函数内部，可以使用更简略的:= 方式声明并初始化变量。(只能在函数体内) package main import { \"fmt\" } var name = \"miaomiao\" func main() { age := 25 name := \"gaojila\"//局部变量name fmt.Println(name,age) } ","date":"2019-08-18","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/:6:0","tags":["Golang(变量)"],"title":"从零开始学习Golang(变量)","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/"},{"categories":["GO"],"content":"匿名变量 在使用多重赋值时，如果想要忽略某个值，可以使用匿名变量（anonymous variable）。 匿名变量用一个下划线_表示。 x,_ := 1 _,y := 2 常量 相对于变量，常量是恒定不变到值，多用于程序运行期间不会改变的那些值。常量的声明和变量的声明非常的类似，只是把var换成了const,常量在定义的时候必须赋值。 const pi = 3.14159 const e = 2.71 多个常量也可以一起声明 const { pi = 3.14159 e =2.71 } const 同时声明多个常量时，如果省略了值则表示和上面一行的值相同。 const { a = 1 b c d } ","date":"2019-08-18","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/:7:0","tags":["Golang(变量)"],"title":"从零开始学习Golang(变量)","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/"},{"categories":["GO"],"content":"iota iota是 go 语言中的常量计数器，只能在常量表达式中使用。 iota在 const 关键字出现的时候将被重置为 0。const 每新增一行常量声明将使iota计数一次。 const { a = iota //0 b //1 c //2 d //3 } ","date":"2019-08-18","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/:8:0","tags":["Golang(变量)"],"title":"从零开始学习Golang(变量)","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/"},{"categories":["GO"],"content":"常见 iota 示例： 使用_跳过某些值 const { a = iota //0 b //1 _ d //3 } 声明中间插队 const { a = iota //0 b = 100 c = iota //2 d //3 } 定义数量级 const { _ = iota KB = 1 \u003c\u003c (10 * iota) . . . . PB = 1 \u003c\u003c (10 * iota) } 多个iota\u003e定义在一行 const { a,b = iota+1,iota+2 //1,2 c,d //2,3 e,f //3,4 } ","date":"2019-08-18","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/:9:0","tags":["Golang(变量)"],"title":"从零开始学习Golang(变量)","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6golang-%E5%8F%98%E9%87%8F/"},{"categories":["linux(🐧)"],"content":"场景 个业务系统无法生成订单,订单报错和 gearman 的 worker 有关，使用 curl 调用接口发现报 500 错误。 过程 curl 调用接口不通 登录 gearman 服务器调用接口不通 重启 gearman worker 调用不通 查看接口服务是由 lighttp 提供 直接调用 80 端口不通 重启 lighttp 调用成功 原因 生物信息升级了 python ","date":"2019-08-17","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1gearman%E6%95%85%E9%9A%9C%E8%B0%83%E6%9F%A5/:0:0","tags":["记一次gearman故障调查"],"title":"记一次gearman故障调查","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1gearman%E6%95%85%E9%9A%9C%E8%B0%83%E6%9F%A5/"},{"categories":["linux(🐧)"],"content":"前言 都是别人的链接有时间再自己整理 链接 top 介绍 tar 命令 linux 下压缩命令大全 linux 常用命令简单介绍(netstat,awk,top,tail,head,less,more,cat,nl) linux 下查看文件和文件夹大小 linux 常用命令(替换) 安装及应用管理程序 linux 系统故障排查和修复技巧 mount 命令详解 linux 常用命令总结(一) linux 常用命令总结(二) linux 常用命令总结(三) linux 异常 详细解析 linux /etc/passwd 文件 理解 linux 系统中的 load average(图文版) linux 注销其他用户 linux 自启动方法 Linux 网络接口配置文件 ifcfg-eth0 解析 linux 基础知识总结 linux 基础知识总结 2 linux 批量 kill 进程 ","date":"2019-08-17","objectID":"/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/:0:0","tags":["linux常用命令详解"],"title":"linux常用命令详解","uri":"/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"},{"categories":["Git"],"content":"场景 有时候已经提交到远程仓库的代码希望回滚该怎么做？ 有时候有多个 commit 该如何合并成一个提交？ 方法 使用 git rebase 合并多个 commit git rebase -l \u003c版本号\u003e 使用 git rebase 回滚已经提交 git reset --soft \u003c版本号\u003e git push origin master --force 注意 需要在 web 端关闭分支保护，然后重新 git add ","date":"2019-08-16","objectID":"/gitrest%E4%B8%8Egitrebase/:0:0","tags":["gitrest与gitrebase"],"title":"gitrest与gitrebase","uri":"/gitrest%E4%B8%8Egitrebase/"},{"categories":["Git"],"content":"场景 github 上 fork 原项目，如何将本仓库更新到最新版本？ 方法 配置当前 fork 仓库的原地址 git remote add upstream \u003c原仓库github地址\u003e 查看当前仓库的远程仓库地址和原仓库地址 git remote -v 获取原仓库的更新。使用 fetch 更新，fetch 后会被存储在一个本地分支 upstream/master 上 git fetch upstream 合并到本地分支。切换到 master 分支，合并 upstream/master 分支。 git merge upstream/master 这个时候使用 git log 就用看到原仓库的更新了。 git log 如果需要自己的 github 上的 fork 的仓库保持同步更新，执行 git push 进行推送。 git push origin master 如果出现无法提交时，强制覆盖。 git fetch origin git reset --hard origin/master ","date":"2019-08-16","objectID":"/git%E8%8E%B7%E5%8F%96%E4%B8%8E%E5%8E%9F%E4%BB%93%E5%BA%93%E5%90%8C%E6%AD%A5%E6%9B%B4%E6%96%B0/:0:0","tags":["git获取与原仓库同步更新"],"title":"git获取与原仓库同步更新","uri":"/git%E8%8E%B7%E5%8F%96%E4%B8%8E%E5%8E%9F%E4%BB%93%E5%BA%93%E5%90%8C%E6%AD%A5%E6%9B%B4%E6%96%B0/"},{"categories":["容器(🚢)"],"content":"前言 使用新工具 podman 搭建 docker 私有仓库下面简述 podman 的优点 podman 无守护进程 每一个容器就是一个进程 非 root 用户也可执行 podman 命令和 docker 命令大体一致 方法 ","date":"2019-08-09","objectID":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/:0:0","tags":["搭建docker私有仓库"],"title":"podman搭建nexus3私有仓库","uri":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"},{"categories":["容器(🚢)"],"content":"ubuntu 安装 podman sudo apt update sudo apt -y install software-properties-common sudo add-apt-repository -y ppa:projectatomic/ppa sudo apt install podman -y ","date":"2019-08-09","objectID":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/:1:0","tags":["搭建docker私有仓库"],"title":"podman搭建nexus3私有仓库","uri":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"},{"categories":["容器(🚢)"],"content":"podman 启动 nexus 容器 podman run -d -p 8081:8081 -p 8082:8082 -p 8083:8083 -v /data/nexus3_podman:/nexus-data --name nexus3 docker.io/sonatype/nexus3 ","date":"2019-08-09","objectID":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/:2:0","tags":["搭建docker私有仓库"],"title":"podman搭建nexus3私有仓库","uri":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"},{"categories":["容器(🚢)"],"content":"podman 查看容器启动日志 podman logs -f nexus3 ","date":"2019-08-09","objectID":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/:3:0","tags":["搭建docker私有仓库"],"title":"podman搭建nexus3私有仓库","uri":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"},{"categories":["容器(🚢)"],"content":"添加仓库(hosted,proxy,group) 样列 配置 ","date":"2019-08-09","objectID":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/:4:0","tags":["搭建docker私有仓库"],"title":"podman搭建nexus3私有仓库","uri":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"},{"categories":["容器(🚢)"],"content":"使用 nginx 代理方式将 pull 和 push 合并成一个端口 upstream nexus_docker_get { server 192.168.157.110:8082; } upstream nexus_docker_put { server 192.168.157.110:8083; } server { listen 80; listen 443 ssl; server_name idocker.io; access_log /var/log/nginx/idocker.io.log; # 证书 ssl_certificate /usr/local/nginx/conf/ssl/out/idocker.io/idocker.io.crt; ssl_certificate_key /usr/local/nginx/conf/ssl/out/cert.key.pem; ssl_protocols TLSv1.1 TLSv1.2; ssl_ciphers '!aNULL:kECDH+AESGCM:ECDH+AESGCM:RSA+AESGCM:kECDH+AES:ECDH+AES:RSA+AES:'; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; # disable any limits to avoid HTTP 413 for large image uploads client_max_body_size 0; # required to avoid HTTP 411: see Issue #1486 (https://github.com/docker/docker/issues/1486) chunked_transfer_encoding on; # 设置默认使用推送代理 set $upstream \"nexus_docker_put\"; # 当请求是GET，也就是拉取镜像的时候，这里改为拉取代理，如此便解决了拉取和推送的端口统一 if ( $request_method ~* 'GET') { set $upstream \"nexus_docker_get\"; } index index.html index.htm index.php; location / { proxy_pass http://$upstream; proxy_set_header Host $host; proxy_connect_timeout 3600; proxy_send_timeout 3600; proxy_read_timeout 3600; proxy_set_header X-Real-IP $remote_addr; proxy_buffering off; proxy_request_buffering off; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto http; } } 坑 在映射外部路径时需要将映射目录的 owner 改为 200(nexus 的 uid 和 gid) ","date":"2019-08-09","objectID":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/:5:0","tags":["搭建docker私有仓库"],"title":"podman搭建nexus3私有仓库","uri":"/podman%E6%90%AD%E5%BB%BAnexus3%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/"},{"categories":["容器(🚢)"],"content":"login docker login \u003chost\u003e pull docker pull \u003chost\u003e/\u003cporject\u003e/\u003crepo\u003e:\u003ctag\u003e push 重新打 tag docker tag \u003cimg_name\u003e:\u003ctage\u003e \u003chost\u003e/\u003cproject\u003e/\u003crepo\u003e:\u003ctag\u003e push docker push \u003chost\u003e/\u003cporject\u003e/\u003crepo\u003e:\u003ctag\u003e ","date":"2019-08-09","objectID":"/docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93pull%E5%92%8Cpush/:0:0","tags":["nexus3 docker pull or push"],"title":"docker私有仓库pull和push","uri":"/docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93pull%E5%92%8Cpush/"},{"categories":["Prometheus"],"content":"前言 zabbix 对于运维人员来说无法完全做到自动化,内部业务即将 docker 化,故有将 zabbix 替换为 prometheus 的想法 这篇文档将会更新很久 参照此文档未完 参考此文档 Prometheus 搭建 ","date":"2019-08-03","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/:0:0","tags":["Prometheus + Grafana"],"title":"Prometheus 监控系统搭建","uri":"/prometheus%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/"},{"categories":["Prometheus"],"content":"supervisor 守护进程方式 github 下载最新二进制包 # 使用的包时github的最新稳定版包 wget https://github.com/prometheus/prometheus/releases/download/v2.17.1/prometheus-2.17.1.linux-amd64.tar.gz 将下载的二进制包解压到你想要放到的目录下 supervisor 守护进程配置 ","date":"2019-08-03","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/:1:0","tags":["Prometheus + Grafana"],"title":"Prometheus 监控系统搭建","uri":"/prometheus%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/"},{"categories":["Prometheus"],"content":"docker 方式 Node_exporter 搭建 Alertmanage 搭建 Grafana 搭建 Prometheus 常用内置函数 Prometheus 自定义监控 Alertmanage 告警路由 Prometheus 告警规则 Grafana 配置告警 Grafana 画图 ","date":"2019-08-03","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/:2:0","tags":["Prometheus + Grafana"],"title":"Prometheus 监控系统搭建","uri":"/prometheus%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/"},{"categories":["greenplum"],"content":"备份工具选择 ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:0:0","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"gpcrondump ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:1:0","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"说明 gpcrondump 实用程序将数据库的内容转储为 SQL 脚本文件，然后可以使用它们在以后使用它来还原数据库架构和用户数据 gpdbrestore。在转储操作期间，用户仍将具有对数据库的完全访问权限。 ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:1:1","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"缺点 Backing up a database with gpcrondump while simultaneously running ALTER TABLE might cause gpcrondump to fail. Backing up a database with gpcrondump while simultaneouslyrunning DDL commands might cause issues with locks. You might see either the DDL command or gpcrondump waiting to acquire locks. 大概就是运行的时候更改表会备份失败,运行 DDL 会产生锁表问题 ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:1:2","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"gpbackup ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:2:0","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"说明 将数据库的内容备份到元数据文件和数据文件的集合中，这些文件和数据文件可用于以后使用它来还原数据库 gprestore。 默认情况下， gpbackup 备份指定数据库中的对象以及全局 Greenplum 数据库系统对象。您可以选择提供-globals 选项 gprestore 恢复全局对象. gpbackup 默认情况下，将对象元数据文件和 DDL 文件存储在 Greenplum 数据库主数据目录中。Greenplum 数据库细分使用复制..关于部分命令将备份表的数据存储在位于每个段的数据目录中的压缩 CSV 数据文件中。 ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:2:1","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"安装 gpbackup 由 go 编写，可一次编译到处执行。 源码编译安装 ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:2:2","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"参数 -dbname database_name 需要。指定要备份的数据库。 -backupdir 目录 可选的。将所有必需的备份文件（元数据文件和数据文件）复制到指定的目录。您必须将目录指定为绝对路径（不是相对路径）。如果您不提供此选项，则会在$ MASTER_DATA_DIRECTORY / backups / YYYYMMDD / YYYYMMDDhhmmss / 目录中的Greenplum Database主机上创建元数据文件 。段主机在\u003cseg_dir\u003e / backups / YYYYMMDD / YYYYMMDDhhmmss /目录中创建CSV数据文件 。指定自定义备份目录时，会将文件复制到备份目录的子目录中的这些路径。 -data-only 可选的。仅将表数据备份到CSV文件中，但不备份重新创建表和其他数据库对象所需的元数据文件。 -debug 可选的。在操作期间显示详细的调试消息。 -exclude-schema schema_name 可选的。指定要从备份中排除的数据库模式。您可以多次指定此选项以排除多个模式。您无法将此选项与-include-模式选项。有关详细信息，请参阅筛选备份的内容。 -exclude-table-file file_name 可选的。指定包含要从备份中排除的表列表的文本文件。文本文件中的每一行都必须使用该格式定义一个表 \u003c模式名称\u003e \u003c表名\u003e。该文件不得包含尾随行。如果表或模式名称使用小写字母，数字或下划线字符以外的任何字符，则必须在双引号中包含该名称。 您不能结合使用此选项 -leaf分区数据。虽然您可以在指定的文件中指定叶子分区名称 -exclude表文件， gpbackup 忽略分区名称。 有关 详细信息，请参阅筛选备份的内容。 -include-schema schema_name 可选的。指定要包括在备份中的数据库模式。您可以多次指定此选项以包含多个模式。如果指定此选项，则后续未包含的任何模式-include-模式备份集中省略了选项。您无法将此选项与 -exclude-模式选项。有关详细信息，请参阅筛选备份的内容。 -include-table-file file_name 可选的。指定包含要包括在备份中的表列表的文本文件。文本文件中的每一行都必须使用该格式定义一个表 \u003c模式名称\u003e \u003c表名\u003e。该文件不得包含尾随行。如果表或模式名称使用小写字母，数字或下划线字符以外的任何字符，则必须在双引号中包含该名称。备份集中将省略此文件中未列出的任何表。 您可以选择指定表叶子分区名称来代替表名称，以便在备份中仅包含特定叶子分区 -leaf分区数据 选项。 有关 详细信息，请参阅筛选备份的内容。 --leaf-partition-data 可选的。对于分区表，为每个叶子分区创建一个数据文件，而不是为整个表创建一个数据文件（默认值）。使用此选项还可以指定要包含在备份中的单个叶子分区 -include表文件选项。您不能结合使用此选项-exclude表文件。 --metadata-only 可选的。仅创建重新创建数据库对象所需的元数据文件（DDL），但不备份实际的表数据。 --no-compression 可选的。不要压缩表数据CSV文件。 --quiet 可选的。禁止所有非警告，非错误日志消息。 -verbose 可选的。打印详细日志消息。 --version 可选的。打印版本号并退出。 --with-stats 可选的。在备份集中包含查询计划统计信息。 gpbackup 备份实例说明 ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:2:3","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"完全备份 gpadmin@gpmaster:~$ gpbackup --dbname test --backup-dir /var/tmp/0715 --leaf-partition-data 20190716:10:25:59 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Starting backup of database test 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Backup Timestamp = 20190716102559 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Backup Database = test 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Gathering table state information 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Acquiring ACCESS SHARE locks on tables Locks acquired: 1 / 1 [============================================================] 100.00% 0s 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Gathering additional table metadata 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Metadata will be written to /var/tmp/0715/gpseg-1/backups/20190716/20190716102559/gpbackup_20190716102559_metadata.sql 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Writing global database metadata 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Metadata will be written to /var/tmp/0715/gpseg-1/backups/20190716/20190716102559/gpbackup_20190716102559_metadata.sql 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Writing global database metadata 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Global database metadata backup complete 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Writing pre-data metadata 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Pre-data metadata backup complete 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Writing post-data metadata 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Post-data metadata backup complete 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Writing data to file Tables backed up: 1 / 1 [==========================================================] 100.00% 0s 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Data backup complete 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Writing data to file Tables backed up: 1 / 1 [==========================================================] 100.00% 0s 20190716:10:26:00 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Data backup complete 20190716:10:26:01 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Found neither /opt/gpdb/bin/gp_email_contacts.yaml nor /home/gpadmin/gp_email_contacts.yaml 20190716:10:26:01 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Email containing gpbackup report /var/tmp/0715/gpseg-1/backups/20190716/20190716102559/gpbackup_20190716102559_report will not be sent 20190716:10:26:01 gpbackup:gpadmin:gpmaster:003082-[INFO]:-Backup completed successfully ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:3:0","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"增量备份 gpadmin@gpmaster:~$ gpbackup --dbname test --backup-dir /var/tmp/0715 --leaf-partition-data --incremental 20190716:10:27:08 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Starting backup of database test 20190716:10:27:08 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Backup Timestamp = 20190716102708 20190716:10:27:08 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Backup Database = test 20190716:10:27:08 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Gathering table state information 20190716:10:27:08 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Acquiring ACCESS SHARE locks on tables Locks acquired: 2 / 2 [============================================================] 100.00% 0s 20190716:10:27:08 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Gathering additional table metadata 20190716:10:27:08 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Metadata will be written to /var/tmp/0715/gpseg-1/backups/20190716/20190716102708/gpbackup_20190716102708_metadata.sql 20190716:10:27:08 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Writing global database metadata 20190716:10:27:08 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Global database metadata backup complete 20190716:10:27:08 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Writing pre-data metadata 20190716:10:27:09 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Pre-data metadata backup complete 20190716:10:27:09 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Writing post-data metadata 20190716:10:27:09 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Post-data metadata backup complete 20190716:10:27:09 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Basing incremental backup off of backup with timestamp = 20190716102559 20190716:10:27:09 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Writing data to file Tables backed up: 2 / 2 [==========================================================] 100.00% 0s 20190716:10:27:09 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Data backup complete 20190716:10:27:10 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Found neither /opt/gpdb/bin/gp_email_contacts.yaml nor /home/gpadmin/gp_email_contacts.yaml 20190716:10:27:10 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Email containing gpbackup report /var/tmp/0715/gpseg-1/backups/20190716/20190716102708/gpbackup_20190716102708_report will not be sent 20190716:10:27:10 gpbackup:gpadmin:gpmaster:003120-[INFO]:-Backup completed successfully ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:4:0","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"表级别备份 gpadmin@gsdw_dev-master:~$ gpbackup --dbname gsdw --backup-dir /data/gpbackup --include-table dw_agg.agg_cus_fct_category_for_mkt 20190801:14:51:46 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Starting backup of database gsdw 20190801:14:51:46 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Backup Timestamp = 20190801145145 20190801:14:51:46 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Backup Database = gsdw 20190801:14:51:46 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Gathering table state information 20190801:14:51:46 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Acquiring ACCESS SHARE locks on tables Locks acquired: 1 / 1 [==================================================] 100.00% 0s 20190801:14:51:46 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Gathering additional table metadata 20190801:14:51:46 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Metadata will be written to /data/gpbackup/gpseg-1/backups/20190801/20190801145145/gpbackup_20190801145145_metadata.sql 20190801:14:51:46 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Writing pre-data metadata 20190801:14:51:46 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Pre-data metadata backup complete 20190801:14:51:46 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Writing post-data metadata 20190801:14:51:47 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Post-data metadata backup complete 20190801:14:51:47 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Writing data to file Tables backed up: 1 / 1 [================================================] 100.00% 0s 20190801:14:51:47 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Data backup complete 20190801:14:51:48 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Found neither /opt/gpdb/bin/gp_email_contacts.yaml nor /home/gpadmin/gp_email_contacts.yaml 20190801:14:51:48 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Email containing gpbackup report /data/gpbackup/gpseg-1/backups/20190801/20190801145145/gpbackup_20190801145145_report will not be sent 20190801:14:51:48 gpbackup:gpadmin:gsdw_dev-master:016502-[INFO]:-Backup completed successfully ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:5:0","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"备份恢复 gpadmin@gpmaster:~$ gprestore -backup-dir /var/tmp/0715 -timestamp 20190715101501 --create-db 20190715:10:16:17 gprestore:gpadmin:gpmaster:002765-[INFO]:-Restore Key = 20190715101501 20190715:10:16:17 gprestore:gpadmin:gpmaster:002765-[INFO]:-Restoring pre-data metadata Pre-data objects restored: 8 / 8 [=================================================] 100.00% 0s 20190715:10:16:18 gprestore:gpadmin:gpmaster:002765-[INFO]:-Pre-data metadata restore complete Tables restored: 2 / 2 [===========================================================] 100.00% 0s 20190715:10:16:18 gprestore:gpadmin:gpmaster:002765-[INFO]:-Data restore complete 20190715:10:16:18 gprestore:gpadmin:gpmaster:002765-[INFO]:-Restoring post-data metadata Post-data objects restored: 2 / 2 [================================================] 100.00% 0s 20190715:10:16:18 gprestore:gpadmin:gpmaster:002765-[INFO]:-Post-data metadata restore complete 20190715:10:16:18 gprestore:gpadmin:gpmaster:002765-[INFO]:-Found neither /opt/gpdb/bin/gp_email_contacts.yaml nor /home/gpadmin/gp_email_contacts.yaml 20190715:10:16:18 gprestore:gpadmin:gpmaster:002765-[INFO]:-Email containing gprestore report /var/tmp/0715/gpseg-1/backups/20190715/20190715101501/gprestore_20190715101501_20190715101617_report will not be sent 20190715:10:16:18 gprestore:gpadmin:gpmaster:002765-[INFO]:-Restore completed successfully ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:6:0","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"表级别恢复 gpadmin@gsdw_dev-master:~$ gprestore --backup-dir /var/tmp/0724 --timestamp 20190724132252 --include-table test.test_user_tb 20190724:14:32:03 gprestore:gpadmin:gsdw_dev-master:001423-[INFO]:-Restore Key = 20190724132252 20190724:14:32:04 gprestore:gpadmin:gsdw_dev-master:001423-[INFO]:-Restoring pre-data metadata Pre-data objects restored: 0 / 11 [-------------------------------------------------------] 0.00%20190724:14:32:05 gprestore:gpadmin:gsdw_dev-master:001423-[WARNING]:-Schema meta_data already exists 20190724:14:32:05 gprestore:gpadmin:gsdw_dev-master:001423-[WARNING]:-Schema test already exists Pre-data objects restored: 11 / 11 [===================================================] 100.00% 1s 20190724:14:32:07 gprestore:gpadmin:gsdw_dev-master:001423-[INFO]:-Pre-data metadata restore complete Tables restored: 1 / 1 [===============================================================] 100.00% 0s 20190724:14:32:09 gprestore:gpadmin:gsdw_dev-master:001423-[INFO]:-Data restore complete 20190724:14:32:09 ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:7:0","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"备份恢复前后比较 备份前表结构 备份前数据量 删除 cn_accounting_ar_invoice_lines 表做恢复演示 备份恢复后表结构 备份恢复后数据量 注意事项（坑） gpbackup 需要下载放到 greenplum 的环境变量中去 gprestore 恢复数据的前提 greenplum 有这个要恢复的数据库且数据库要是空的………. gprestore 恢复表的前提 greenplum 要恢复的表是空的………. 备份和和恢复最好指定备份路径,不然恢复的时候找不到……… 如果要使用增量备份,在全备份的时候需要加（ –leaf-partition-data)参数………… 详细说明请见官方文档 ","date":"2019-07-16","objectID":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:8:0","tags":["greenplum使用gpbackup"],"title":"greenplum并行备份与恢复","uri":"/greenplum%E5%B9%B6%E8%A1%8C%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["greenplum"],"content":"所有节点操作 ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:0:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["greenplum"],"content":"所有节点安装 greenplum add-apt-repository ppa:greenplum/db apt-get update apt-get install greenplum-db-oss ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:1:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["greenplum"],"content":"将所有节点添加到 hosts 文件中 172.16.132.134 gpmaster 172.16.132.136 gpslave 172.16.132.135 gpsegment1 172.16.132.137 gpsegment2 ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:2:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["greenplum"],"content":"添加 gpadmin 用户 groupadd gpadmin useradd -m -g gpadmin -s /bin/bash gpadmin ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:3:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["greenplum"],"content":"更改系统参数 vim /etc/sysctl.conf kernel.shmmax = 500000000 kernel.shmmni = 4096 kernel.shmall = 4000000000 kernel.sem = 250 512000 100 2048 kernel.sysrq = 1 kernel.core_uses_pid = 1 kernel.msgmnb = 65536 kernel.msgmax = 65536 kernel.msgmni = 2048 net.ipv4.tcp_syncookies = 1 net.ipv4.conf.default.accept_source_route = 0 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.conf.all.arp_filter = 1 net.ipv4.ip_local_port_range = 1025 65535 net.core.netdev_max_backlog = 10000 net.core.rmem_max = 2097152 net.core.wmem_max = 2097152 vm.overcommit_memory = 2 vm.overcommit_ratio = 95 net.ipv4.ip_forward = 0 vim /etc/security/limits.conf * soft nofile 65536 * hard nofile 65536 * soft nproc 131072 * hard nproc 131072 ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:4:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["greenplum"],"content":"设置 ntp echo \"server pgmaster\" \u003e\u003e /etc/ntp.conf systemctl restart ntpd ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:5:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["greenplum"],"content":"设置 segments 数据目录存储参数(仅在 segment 机器上执行即可) blockdev --setra 16384 /dev/sda ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:6:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["greenplum"],"content":"重启机器 reboot master 节点操作 ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:7:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["greenplum"],"content":"创建 data 目录 mkdir -p /data/master chown -R gpadmin:gpadmin /data ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:8:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["greenplum"],"content":"配置环境变量 echo \"source /opt/gpdb/greenplum_path.sh\" \u003e\u003e /home/gpadmin/.bashrc source .bashrc ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:9:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["greenplum"],"content":"初始化 greenplum(gpadmin 用户家目录下) 新建 allhosts gpmaster gpslave gpsegment1 gpsegment2 新建 seghosts gpsegment1 gpsegment2 修改初始化配置 cp /opt/gpdb/docs/cli_help/gpconfigs/gpinitsystem_config . \u0026\u0026 vim gpinitsystem_config ( declare -a DATA_DIRECTORY=(/data/primary ) MASTER_HOSTNAME=gpmaster MASTER_DIRECTORY=/data/master MIRROR_PORT_BASE=50000 REPLICATION_PORT_BASE=41000 MIRROR_REPLICATION_PORT_BASE=51000 ) 配置免密钥登录 gpssh-exkeys -f allhosts 在各节点新建数据目录 gpssh -h gsdw-standby -e 'mkdir -p /data/master' gpssh -f hostfile_seg -e 'mkdir -p /data/primary' gpssh -f hostfile_seg -e 'mkdir -p /data/mirror' 补充参数设置(root 用户下执行) echo \"RemoveIPC=no\" \u003e\u003e /etc/systemd/logind.conf service systemd-logind restart 执行数据库初始化 gpinitsystem -c gpinitsystem_config -h seghosts gpinitstandby -s gpslave 将数据目录加入到环境变量 echo \"export MASTER_DATA_DIRECTORY=/data/master/gpseg-1/\" \u003e\u003e /home/gpadmin/.bashrc 备注 pgsql postgres(greenplum 没有 pgadmin 库不能 psql 直接进入数据库) ","date":"2019-07-04","objectID":"/greenplum%E5%AE%89%E8%A3%85/:10:0","tags":["greenplum ubuntu 16.04安装"],"title":"greenplum安装","uri":"/greenplum%E5%AE%89%E8%A3%85/"},{"categories":["postgresql"],"content":"pg_rman 工具 pg_rman 是 PostgreSQL 的备份与恢复工具，支持全量、增量、归档三种备方式。 pg_rman 安装 pg_rman 没有 deb 包,需要编译安装。 ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:0:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"开源使用文档 http://ossc-db.github.io/pg_rman/index.html ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:1:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"下载链接 https://github.com/ossc-db/pg_rman/releases ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:2:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"编译安装 解压压缩包后,在安装目录下 make \u0026\u0026 make install ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:3:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"安装注意事项 一定要下载和本机 pgsql 版本相同的压缩包编译安装 依赖(libpq-dev\\postgresql-server-dev-all\\libpam0g-dev\\libedit-dev\\libselinux1-dev) pg_rman 默认安装在 postgresql 的 bin 目录下 pg_rman 使用 ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:4:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"使用前注意事项 新建 BACKUP_PATH\\SRVLOG_PATH\\ARCLOG_PATH(归档日志目录)并设置主:组为 postgres pg_rman 需要加入环境变量 export PGDATA=/var/lib/postgresql/9.5/main export PATH=/usr/lib/postgresql/9.5/bin:$PATH export ARCLOG_PATH=/tmp/postgres/arc_log export SRVLOG_PATH=/tmp/postgres/pg_log export BACKUP_PATH=/tmp/postgres/backup 配置 postgresql.conf 开启日志归档,配置完成后重启 postgresql wal_level = archive archive_mode = on archive_command = 'cp %p /tmp/postgres/arc_log/%f' archive_timeout = 60 初始化备份目录 pg_rman init -B /tmp/postgres/backup su postgres 进入postgres用户下执行备份操作，若使用其他用户备份会导致 备份恢复后权限不对无法启动postgresql 使用 pg_rman 备份 ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:5:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"全量备份 postgres@C01U16BOX02:~$ pg_rman backup -b full INFO: copying database files INFO: copying archived WAL files INFO: backup complete INFO: Please execute 'pg_rman validate' to verify the files are correctly copied. postgres@C01U16BOX02:~$ pg_rman validate INFO: validate: \"2019-07-03 15:52:08\" backup and archive log files by CRC INFO: backup \"2019-07-03 15:52:08\" is valid ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:6:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"增量备份 postgres@C01U16BOX02:~$ pg_rman backup -b incremental INFO: copying database files INFO: copying archived WAL files INFO: backup complete INFO: Please execute 'pg_rman validate' to verify the files are correctly copied. ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:7:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"备份校验 每次备份结束必须做一次校验，否则备份不能用来恢复，增量备份时也不会用它来做增量比较 postgres@C01U16BOX02:~$ pg_rman validate INFO: validate: \"2019-07-03 15:52:08\" backup and archive log files by CRC INFO: backup \"2019-07-03 15:52:08\" is valid ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:8:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"查看备份 postgres@C01U16BOX02:~$ pg_rman show ===================================================================== StartTime EndTime Mode Size TLI Status ===================================================================== 2019-07-03 15:52:08 2019-07-03 15:52:28 FULL 86MB 1 OK 2019-07-03 15:51:02 2019-07-03 15:51:05 INCR 45MB 1 OK 2019-07-03 15:49:58 2019-07-03 15:50:00 INCR 61MB 1 OK 2019-07-03 15:46:13 2019-07-03 15:46:17 FULL 68MB 1 OK 使用 pg_rman 进行恢复 ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:9:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"注意事项 恢复数据必须实在 postgresql 停止的状态下 恢复前请使用 pg_rman show 查看所需要恢复的时间点 ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:10:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"恢复操作 pg_rman restore [options:] #不指定options则默认恢复到最近一次全量备份 --recovery-target-time #指定恢复时间点 postgres@C01U16BOX02:~$ pg_rman restore --recovery-target-time \"2019-07-03 15:51:02\" INFO: the recovery target timeline ID is not given INFO: use timeline ID of current database cluster as recovery target: 1 INFO: calculating timeline branches to be used to recovery target point INFO: searching latest full backup which can be used as restore start point INFO: found the full backup can be used as base in recovery: \"2019-07-03 15:46:13\" INFO: copying online WAL files and server log files INFO: clearing restore destination INFO: validate: \"2019-07-03 15:46:13\" backup and archive log files by SIZE INFO: backup \"2019-07-03 15:46:13\" is valid INFO: restoring database files from the full mode backup \"2019-07-03 15:46:13\" INFO: searching incremental backup to be restored INFO: validate: \"2019-07-03 15:49:58\" backup and archive log files by SIZE INFO: backup \"2019-07-03 15:49:58\" is valid INFO: restoring database files from the incremental mode backup \"2019-07-03 15:49:58\" INFO: searching backup which contained archiv ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:11:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["postgresql"],"content":"备注 详细文档可见 github ","date":"2019-07-03","objectID":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/:12:0","tags":["pg_rman备份"],"title":"pg_rman备份postgresql","uri":"/pg-rman%E5%A4%87%E4%BB%BDpostgresql/"},{"categories":["GO"],"content":"os 常用导出函数 func Hostname() (name string, err error) // Hostname 返回内核提供的主机名 func Hostname() (name string, err error) // Hostname 返回内核提供的主机名 func Environ() []string // Environ 返回表示环境变量的格式为\"key=value\"的字符串的切片拷贝 func Getenv(key string) string // Getenv 检索并返回名为 key 的环境变量的值 func Getpid() int // Getpid 返回调用者所在进程的进程 ID func Exit(code int) // Exit 让当前程序以给出的状态码 code 退出。一般来说，状态码 0 表示成功，非 0 表示出错。程序会立刻终止，defer 的函数不会被执行 func Stat(name string) (fi FileInfo, err error) // 获取文件信息 func Getwd() (dir string, err error) // Getwd 返回一个对应当前工作目录的根路径 func Mkdir(name string, perm FileMode) error // 使用指定的权限和名称创建一个目录 func MkdirAll(path string, perm FileMode) error // 使用指定的权限和名称创建一个目录，包括任何必要的上级目录，并返回 nil，否则返回错误 func Remove(name string) error // 删除 name 指定的文件或目录 func TempDir() string // 返回一个用于保管临时文件的默认目录 var Args []string Args 保管了命令行参数，第一个是程序名。 ","date":"2019-05-05","objectID":"/golang-os%E5%8C%85%E7%94%A8%E6%B3%95/:0:0","tags":["os包用法"],"title":"Golang os包用法","uri":"/golang-os%E5%8C%85%E7%94%A8%E6%B3%95/"},{"categories":["Mysql"],"content":"IP 规划 10.1.1.22(master) 10.1.1.21(master ca) 10.1.1.20(slave) 172.18.36.75(manager) 安装前准备工作 ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:0:0","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"master 与 slave 之间配置 ssh 免密钥登录 ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:1:0","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"mha 依赖与主从复制，请提前配置好主从复制 安装 mha node ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:2:0","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"安装 perl 环境 ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:3:0","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"下载 cpanm wget http://xrl.us/cpanm --no-check-certificate ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:3:1","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"playbook template 模板 #!/bin/bash #================================================================ # Copyright (C) 2019 Sangfor Ltd. All rights reserved. # # 文件名称：install.sh # 创 建 者：luwenzheng # 邮 箱：redgaojila@gmail.com # 创建日期：2019年04月23日 # 描 述： # #================================================================ #!/bin/bash mv /var/tmp/{{ lookup('pipe', 'date +%m%d') }}/cpanm /usr/bin chmod 755 /usr/bin/cpanm cat \u003e /root/list \u003c\u003c EOF install DBD::mysql EOF for package in `cat /root/list` do cpanm $package done ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:3:2","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"node 安装 ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:4:0","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"下载 node deb 包 wget https://github.com/yoshinorim/mha4mysql-node/releases/download/v0.58/mha4mysql-node_0.58-0_all.deb ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:4:1","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"playbook 安装 ---- name:建立备份目录file:\u003epath=\"/var/tmp/{{ lookup('pipe', 'date +%m%d') }}\" state=directory- name:copy 安装包copy:\u003esrc=/home/luwenzheng/ansible/roles/gens.mysqlmha/files/mha4mysql-node_0.58-0_all.deb dest=/var/tmp/{{ lookup('pipe', 'date +%m%d') }}- name:安装node节点shell:dpkg -i /var/tmp/{{ lookup('pipe', 'date +%m%d') }}/mha4mysql-node_0.58-0_all.deb ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:4:2","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"安装完成后可在/usr/bin 下有以下文件 root@nj-lab-0-it:~# dpkg -L mha4mysql-node /. /usr /usr/bin /usr/bin/purge_relay_logs /usr/bin/filter_mysqlbinlog /usr/bin/save_binary_logs /usr/bin/apply_diff_relay_logs /usr/share /usr/share/man /usr/share/man/man1 /usr/share/man/man1/save_binary_logs.1p.gz /usr/share/man/man1/filter_mysqlbinlog.1p.gz /usr/share/man/man1/apply_diff_relay_logs.1p.gz /usr/share/man/man1/purge_relay_logs.1p.gz /usr/share/perl5 /usr/share/perl5/MHA /usr/share/perl5/MHA/BinlogPosFinderElp.pm /usr/share/perl5/MHA/BinlogPosFindManager.pm /usr/share/perl5/MHA/BinlogPosFinderXid.pm /usr/share/perl5/MHA/BinlogPosFinder.pm /usr/share/perl5/MHA/BinlogHeaderParser.pm /usr/share/perl5/MHA/NodeConst.pm /usr/share/perl5/MHA/NodeUtil.pm /usr/share/perl5/MHA/SlaveUtil.pm /usr/share/perl5/MHA/BinlogManager.pm /usr/share/doc /usr/share/doc/mha4mysql-node /usr/share/doc/mha4mysql-node/changelog.Debian.gz /usr/share/doc/mha4mysql-node/AUTHORS /usr/share/doc/mha4mysql-node/README /usr/share/doc/mha4mysql-node/copyright ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:4:3","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"mha manager 安装 ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:5:0","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"下载 manager deb 包 wget https://github.com/yoshinorim/mha4mysql-node/releases/download/v0.58/mha4mysql-manager_0.58-0_all.deb ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:5:1","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"playbook 安装 ---- name:创建备份目录和配置文件目录file:\u003epath={{ item }} state=directorywith_items:- /var/tmp/{{ lookup('pipe', 'date +%m%d') }}- /usr/local/masterha/app1- /etc/masterha- name:创建配置文件file:\u003epath={{ item }} state=touchwith_items:- /etc/masterha/app1/master_ip_failover- /etc/masterha/app1/master_ip_online_change- /etc/masterha/app1/send_report- /etc/masterha/app1/power_manager- /etc/masterha/app1/app1.conf- name:copy 安装包copy:\u003esrc=/home/luwenzheng/ansible/roles/gens.mysqlmha/files/mha4mysql-manager_0.58-0_all.deb dest=/var/tmp/{{ lookup('pipe', 'date +%m%d') }}- name:安装mastershell:dpkg -i /var/tmp/{{ lookup('pipe', 'date +%m%d') }}/mha4mysql-manager_0.58-0_all.deb ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:5:2","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"安装完成后会有以下文件 root@nj-lab-2-it:/var/tmp/0423# dpkg -L mha4mysql-manager /. /usr /usr/bin /usr/bin/masterha_check_status /usr/bin/masterha_check_ssh /usr/bin/masterha_master_monitor /usr/bin/masterha_manager /usr/bin/masterha_master_switch /usr/bin/masterha_stop /usr/bin/masterha_secondary_check /usr/bin/masterha_check_repl /usr/bin/masterha_conf_host /usr/share /usr/share/man /usr/share/man/man1 /usr/share/man/man1/masterha_master_monitor.1p.gz /usr/share/man/man1/masterha_manager.1p.gz /usr/share/man/man1/masterha_secondary_check.1p.gz /usr/share/man/man1/masterha_check_ssh.1p.gz /usr/share/man/man1/masterha_master_switch.1p.gz /usr/share/man/man1/masterha_check_repl.1p.gz /usr/share/man/man1/masterha_stop.1p.gz /usr/share/man/man1/masterha_check_status.1p.gz /usr/share/man/man1/masterha_conf_host.1p.gz /usr/share/perl5 /usr/share/perl5/MHA /usr/share/perl5/MHA/ManagerAdmin.pm /usr/share/perl5/MHA/Server.pm /usr/share/perl5/MHA/MasterRotate.pm /usr/share/perl5/MHA/Config.pm /usr/share/perl5/MHA/ManagerAdminWrapper.pm /usr/share/perl5/MHA/ServerManager.pm /usr/share/perl5/MHA/HealthCheck.pm /usr/share/perl5/MHA/ManagerConst.pm /usr/share/perl5/MHA/DBHelper.pm /usr/share/perl5/MHA/SSHCheck.pm /usr/share/perl5/MHA/FileStatus.pm /usr/share/perl5/MHA/ManagerUtil.pm /usr/share/perl5/MHA/MasterFailover.pm /usr/share/perl5/MHA/MasterMonitor.pm /usr/share/doc /usr/share/doc/mha4mysql-manager /usr/share/doc/mha4mysql-manager/changelog.Debian.gz /usr/share/doc/mha4mysql-manager/AUTHORS /usr/share/doc/mha4mysql-manager/README /usr/share/doc/mha4mysql-manager/copyright ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:5:3","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"文件描述 masterha_check_repl 检查MySQL复制状况 masterha_check_ssh 检查MHA的SSH配置状况 masterha_check_status 检测当前MHA运行状态 masterha_conf_host 添加或删除配置的server信息 masterha_manger 启动MHA masterha_master_monitor 检测master是否宕机 masterha_master_switch 控制故障转移（自动或者手动） ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:5:4","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"mha manager 配置 ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:6:0","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"创建 mha 工作目录 mkdir /etc/masterha ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:6:1","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"app1.cnf 配置 [server default] manager_log=/var/log/masterha/app1-manager.log manager_workdir=/etc/masterha/app1 master_binlog_dir=/var/lib/mysql password=******** ping_interval=5 remote_workdir=/tmp repl_password=******** repl_user=root secondary_check_script=/usr/bin/masterha_secondary_check -s 10.1.1.20 -s 10.1.1.21 --user=root --master_host=10.1.1.22 --master_ip=10.1.1.22 --master_port=3306 shutdown_script=\"\" ssh_user=root user=mha_rep [server2] candidate_master=1 check_repl_delay=0 hostname=10.1.1.21 port=3306 [server3] hostname=10.1.1.20 port=3306 ","date":"2019-04-25","objectID":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/:6:2","tags":["Mysql高可用"],"title":"mysql高可用架构mha安装","uri":"/mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84mha%E5%AE%89%E8%A3%85/"},{"categories":["Mysql"],"content":"主服务器配置 修改 Mysql 配置 vi /etc/msyql/mysql.conf.d/msyqld.conf 在[msyqld]中加 #主数据库端ID号 server_id = 1 #开启二进制日志 log-bin = mysql-bin #需要复制的数据库名，如果复制多个数据库，重复设置这个选项即可 binlog-do-db = db #将从服务器从主服务器收到的更新记入到从服务器自己的二进制日志文件中 log-slave-updates #控制binlog的写入频率。每执行多少次事务写入一次(这个参数性能消耗很大，但可减小MySQL崩溃造成的损失) sync_binlog = 1 #这个参数一般用在主主同步中，用来错开自增值, 防止键值冲突 auto_increment_offset = 1 #这个参数一般用在主主同步中，用来错开自增值, 防止键值冲突 auto_increment_increment = 1 #二进制日志自动删除的天数，默认值为0,表示“没有自动删除”，启动时和二进制日志循环时可能删除 expire_logs_days = 7 #将函数复制到slave log_bin_trust_function_creators = 1 重启 Mysql，创建允许从服务器同步数据的账户 #创建slave账号account，密码123456 mysql\u003egrant replication slave on *.* to 'account'@'10.10.20.116' identified by '123456'; #更新数据库权限 mysql\u003eflush privileges; 查看主服务器状态 mysql\u003eshow master status\\G; ***************** 1. row **************** File: mysql-bin.000033 #当前记录的日志 Position: 337523 #日志中记录的位置 Binlog_Do_DB: Binlog_Ignore_DB: 从服务器配置 修改 mysql 配置 vi /etc/msyql/msyql.conf.d/msyqld.conf 在[mysqld]中添加 server_id = 2 log-bin = mysql-bin log-slave-updates sync_binlog = 0 #log buffer将每秒一次地写入log file中，并且log file的flush(刷到磁盘)操作同时进行。该模式下在事务提交的时候，不会主动触发写入磁盘的操作 innodb_flush_log_at_trx_commit = 0 #指定slave要复制哪个库 binlog-do-db = db #MySQL主从复制的时候，当Master和Slave之间的网络中断，但是Master和Slave无法察觉的情况下（比如防火墙或者路由问题）。Slave会等待slave_net_timeout设置的秒数后，才能认为网络出现故障，然后才会重连并且追赶这段时间主库的数据 slave-net-timeout = 60 log_bin_trust_function_creators = 1 执行同步命令 #执行同步命令，设置主服务器ip，同步账号密码，同步位置 mysql\u003echange master to master_host='10.10.20.111',master_user='account',master_password='123456',master_log_file='mysql-bin.000033',master_log_pos=337523; #开启同步功能 mysql\u003estart slave; 查看从服务器状态 mysql\u003eshow slave status\\G; Slave_IO_State: Waiting for master to send event Master_Host: 10.10.20.111 Master_User: account Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000033 Read_Master_Log_Pos: 337523 Relay_Log_File: db2-relay-bin.000002 Relay_Log_Pos: 337686 Relay_Master_Log_File: mysql-bin.000033 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: ... 查看主服务器中的 slave \u003eshow slave hosts 部署中的坑 因为 1146 错误导致无法同步，在配置文件中添加(slave_skip_errors=1146) ","date":"2019-04-25","objectID":"/ubuntu%E4%B8%8B%E9%85%8D%E7%BD%AEmysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:0:0","tags":["主从复制"],"title":"ubuntu下配置mysql主从复制","uri":"/ubuntu%E4%B8%8B%E9%85%8D%E7%BD%AEmysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["Nginx"],"content":" server { listen 80; server_name **************; auth_basic off; location / { proxy_pass http://************:8081; proxy_set_header Host $host; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 60; proxy_read_timeout 600; proxy_send_timeout 600; } } ","date":"2019-04-25","objectID":"/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%9A%90%E8%97%8F%E7%AB%AF%E5%8F%A3%E5%8F%B7/:0:0","tags":["反向代理"],"title":"nginx反向代理隐藏端口号","uri":"/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%9A%90%E8%97%8F%E7%AB%AF%E5%8F%A3%E5%8F%B7/"}]